{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = \"./\"\n",
    "sampling_rate=100\n",
    "\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "#이 부분이 실행이 안 되시면 prompt에서 sklearn.preprocessing 설치하시면 됩니다\n",
    "Y = pd.read_csv(path + 'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "agg_df = pd.read_csv(path + 'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "empty_indices = Y[Y['diagnostic_superclass'].apply(lambda x: len(x) == 0)].index\n",
    "Y = Y.drop(empty_indices)\n",
    "\n",
    "X = load_raw_data(Y, sampling_rate, path)  \n",
    "\n",
    "test_fold = 10\n",
    "validation_fold = 9\n",
    "\n",
    "X_test = X[Y.strat_fold == test_fold]\n",
    "y_test = Y[Y.strat_fold == test_fold]['diagnostic_superclass']\n",
    "\n",
    "X_validation = X[Y.strat_fold == validation_fold]\n",
    "y_validation = Y[Y.strat_fold == validation_fold]['diagnostic_superclass']\n",
    "\n",
    "X_train = X[(Y.strat_fold != test_fold) & (Y.strat_fold != validation_fold)]\n",
    "y_train = Y[(Y.strat_fold != test_fold) & (Y.strat_fold != validation_fold)]['diagnostic_superclass']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "y_validation_bin = mlb.transform(y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, DeiTForImageClassification\n",
    "from torchvision.models import convnext_tiny, efficientnet_v2_s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Custom Dataset for ECG Data\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = ECGDataset(X_train, y_train_bin, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1 (GPU 1)\n",
      "Training ViT...\n",
      "Starting epoch 1/40...\n",
      "Epoch [1/40], Loss: 0.5519, Accuracy: 0.0524, F1 Score: 0.0422, Precision: 0.2565, Recall: 0.0269\n",
      "Starting epoch 2/40...\n",
      "Epoch [2/40], Loss: 0.5237, Accuracy: 0.2197, F1 Score: 0.1354, Precision: 0.4102, Recall: 0.1166\n",
      "Starting epoch 3/40...\n",
      "Epoch [3/40], Loss: 0.4837, Accuracy: 0.3269, F1 Score: 0.2515, Precision: 0.5325, Recall: 0.2132\n",
      "Starting epoch 4/40...\n",
      "Epoch [4/40], Loss: 0.4598, Accuracy: 0.3629, F1 Score: 0.3275, Precision: 0.5767, Recall: 0.2754\n",
      "Starting epoch 5/40...\n",
      "Epoch [5/40], Loss: 0.4452, Accuracy: 0.3832, F1 Score: 0.4025, Precision: 0.6309, Recall: 0.3336\n",
      "Starting epoch 6/40...\n",
      "Epoch [6/40], Loss: 0.4345, Accuracy: 0.3976, F1 Score: 0.4385, Precision: 0.6417, Recall: 0.3646\n",
      "Starting epoch 7/40...\n",
      "Epoch [7/40], Loss: 0.4285, Accuracy: 0.4086, F1 Score: 0.4536, Precision: 0.6495, Recall: 0.3788\n",
      "Starting epoch 8/40...\n",
      "Epoch [8/40], Loss: 0.4244, Accuracy: 0.4090, F1 Score: 0.4596, Precision: 0.6431, Recall: 0.3867\n",
      "Starting epoch 9/40...\n",
      "Epoch [9/40], Loss: 0.4265, Accuracy: 0.4106, F1 Score: 0.4600, Precision: 0.6449, Recall: 0.3867\n",
      "Starting epoch 10/40...\n",
      "Epoch [10/40], Loss: 0.4305, Accuracy: 0.3994, F1 Score: 0.4487, Precision: 0.6450, Recall: 0.3731\n",
      "Starting epoch 11/40...\n",
      "Epoch [11/40], Loss: 0.4139, Accuracy: 0.4284, F1 Score: 0.4892, Precision: 0.6657, Recall: 0.4157\n",
      "Starting epoch 12/40...\n",
      "Epoch [12/40], Loss: 0.4095, Accuracy: 0.4326, F1 Score: 0.5023, Precision: 0.6678, Recall: 0.4272\n",
      "Starting epoch 13/40...\n",
      "Epoch [13/40], Loss: 0.4061, Accuracy: 0.4377, F1 Score: 0.5090, Precision: 0.6726, Recall: 0.4351\n",
      "Starting epoch 14/40...\n",
      "Epoch [14/40], Loss: 0.4048, Accuracy: 0.4392, F1 Score: 0.5071, Precision: 0.6706, Recall: 0.4331\n",
      "Starting epoch 15/40...\n",
      "Epoch [15/40], Loss: 0.4085, Accuracy: 0.4329, F1 Score: 0.5032, Precision: 0.6687, Recall: 0.4275\n",
      "Starting epoch 16/40...\n",
      "Epoch [16/40], Loss: 0.4000, Accuracy: 0.4468, F1 Score: 0.5243, Precision: 0.6823, Recall: 0.4485\n",
      "Starting epoch 17/40...\n",
      "Epoch [17/40], Loss: 0.3982, Accuracy: 0.4470, F1 Score: 0.5191, Precision: 0.6756, Recall: 0.4447\n",
      "Starting epoch 18/40...\n",
      "Epoch [18/40], Loss: 0.3948, Accuracy: 0.4544, F1 Score: 0.5335, Precision: 0.6809, Recall: 0.4603\n",
      "Starting epoch 19/40...\n",
      "Epoch [19/40], Loss: 0.3949, Accuracy: 0.4522, F1 Score: 0.5322, Precision: 0.6838, Recall: 0.4566\n",
      "Starting epoch 20/40...\n",
      "Epoch [20/40], Loss: 0.3970, Accuracy: 0.4484, F1 Score: 0.5308, Precision: 0.6827, Recall: 0.4554\n",
      "Starting epoch 21/40...\n",
      "Epoch [21/40], Loss: 0.3907, Accuracy: 0.4619, F1 Score: 0.5445, Precision: 0.6860, Recall: 0.4717\n",
      "Starting epoch 22/40...\n",
      "Epoch [22/40], Loss: 0.3950, Accuracy: 0.4573, F1 Score: 0.5371, Precision: 0.6829, Recall: 0.4637\n",
      "Starting epoch 23/40...\n",
      "Epoch [23/40], Loss: 0.3916, Accuracy: 0.4616, F1 Score: 0.5425, Precision: 0.6857, Recall: 0.4698\n",
      "Starting epoch 24/40...\n",
      "Epoch [24/40], Loss: 0.3957, Accuracy: 0.4574, F1 Score: 0.5345, Precision: 0.6844, Recall: 0.4595\n",
      "Early stopping triggered after 24 epochs.\n",
      "ViT training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} (GPU 1)\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "num_classes = y_train_bin.shape[1]\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=40, patience=3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        precision = precision_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        recall = recall_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "print('Training ViT...')\n",
    "train_model(model, dataloader)\n",
    "print('ViT training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DeiT...\n",
      "Starting epoch 1/40...\n",
      "Epoch [1/40], Loss: 0.5563, Accuracy: 0.0789, F1 Score: 0.0568, Precision: 0.2698, Recall: 0.0392\n",
      "Starting epoch 2/40...\n",
      "Epoch [2/40], Loss: 0.5272, Accuracy: 0.1911, F1 Score: 0.1450, Precision: 0.4413, Recall: 0.1126\n",
      "Starting epoch 3/40...\n",
      "Epoch [3/40], Loss: 0.4997, Accuracy: 0.2978, F1 Score: 0.2279, Precision: 0.5108, Recall: 0.1916\n",
      "Starting epoch 4/40...\n",
      "Epoch [4/40], Loss: 0.4939, Accuracy: 0.3142, F1 Score: 0.2607, Precision: 0.5483, Recall: 0.2151\n",
      "Starting epoch 5/40...\n",
      "Epoch [5/40], Loss: 0.4925, Accuracy: 0.3077, F1 Score: 0.2615, Precision: 0.5485, Recall: 0.2134\n",
      "Starting epoch 6/40...\n",
      "Epoch [6/40], Loss: 0.4849, Accuracy: 0.3213, F1 Score: 0.2975, Precision: 0.5729, Recall: 0.2394\n",
      "Starting epoch 7/40...\n",
      "Epoch [7/40], Loss: 0.4884, Accuracy: 0.3101, F1 Score: 0.2724, Precision: 0.5583, Recall: 0.2200\n",
      "Starting epoch 8/40...\n",
      "Epoch [8/40], Loss: 0.4811, Accuracy: 0.3277, F1 Score: 0.2879, Precision: 0.5609, Recall: 0.2356\n",
      "Starting epoch 9/40...\n",
      "Epoch [9/40], Loss: 0.4744, Accuracy: 0.3318, F1 Score: 0.3124, Precision: 0.5786, Recall: 0.2526\n",
      "Starting epoch 10/40...\n",
      "Epoch [10/40], Loss: 0.4810, Accuracy: 0.3284, F1 Score: 0.2958, Precision: 0.5844, Recall: 0.2391\n",
      "Starting epoch 11/40...\n",
      "Epoch [11/40], Loss: 0.4807, Accuracy: 0.3293, F1 Score: 0.3083, Precision: 0.5935, Recall: 0.2486\n",
      "Starting epoch 12/40...\n",
      "Epoch [12/40], Loss: 0.4826, Accuracy: 0.3266, F1 Score: 0.3144, Precision: 0.6038, Recall: 0.2530\n",
      "Early stopping triggered after 12 epochs.\n",
      "DeiT training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torchvision import transforms\n",
    "from torchvision.models import convnext_tiny\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DeiTForImageClassification\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = convnext_tiny(pretrained=True)\n",
    "num_classes = y_train_bin.shape[1]  \n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=40, patience=3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        precision = precision_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        recall = recall_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "model = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
    "num_classes = y_train_bin.shape[1]\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "print('Training DeiT...')\n",
    "train_model(model, dataloader)\n",
    "print('DeiT training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EfficientNetV2...\n",
      "Starting epoch 1/40...\n",
      "Epoch [1/40], Loss: 0.3724, Accuracy: 0.5009, F1 Score: 0.5880, Precision: 0.7039, Recall: 0.5232\n",
      "Starting epoch 2/40...\n",
      "Epoch [2/40], Loss: 0.3209, Accuracy: 0.5655, F1 Score: 0.6690, Precision: 0.7576, Recall: 0.6109\n",
      "Starting epoch 3/40...\n",
      "Epoch [3/40], Loss: 0.3031, Accuracy: 0.5897, F1 Score: 0.6907, Precision: 0.7755, Recall: 0.6337\n",
      "Starting epoch 4/40...\n",
      "Epoch [4/40], Loss: 0.2913, Accuracy: 0.5956, F1 Score: 0.7025, Precision: 0.7793, Recall: 0.6487\n",
      "Starting epoch 5/40...\n",
      "Epoch [5/40], Loss: 0.2807, Accuracy: 0.6075, F1 Score: 0.7147, Precision: 0.7885, Recall: 0.6626\n",
      "Starting epoch 6/40...\n",
      "Epoch [6/40], Loss: 0.2721, Accuracy: 0.6220, F1 Score: 0.7260, Precision: 0.7976, Recall: 0.6750\n",
      "Starting epoch 7/40...\n",
      "Epoch [7/40], Loss: 0.2661, Accuracy: 0.6277, F1 Score: 0.7342, Precision: 0.8020, Recall: 0.6851\n",
      "Starting epoch 8/40...\n",
      "Epoch [8/40], Loss: 0.2562, Accuracy: 0.6408, F1 Score: 0.7437, Precision: 0.8104, Recall: 0.6952\n",
      "Starting epoch 9/40...\n",
      "Epoch [9/40], Loss: 0.2460, Accuracy: 0.6506, F1 Score: 0.7545, Precision: 0.8150, Recall: 0.7091\n",
      "Starting epoch 10/40...\n",
      "Epoch [10/40], Loss: 0.2356, Accuracy: 0.6618, F1 Score: 0.7650, Precision: 0.8247, Recall: 0.7196\n",
      "Starting epoch 11/40...\n",
      "Epoch [11/40], Loss: 0.2248, Accuracy: 0.6721, F1 Score: 0.7757, Precision: 0.8310, Recall: 0.7331\n",
      "Starting epoch 12/40...\n",
      "Epoch [12/40], Loss: 0.2099, Accuracy: 0.6933, F1 Score: 0.7953, Precision: 0.8453, Recall: 0.7554\n",
      "Starting epoch 13/40...\n",
      "Epoch [13/40], Loss: 0.1963, Accuracy: 0.7073, F1 Score: 0.8066, Precision: 0.8529, Recall: 0.7694\n",
      "Starting epoch 14/40...\n",
      "Epoch [14/40], Loss: 0.1769, Accuracy: 0.7293, F1 Score: 0.8282, Precision: 0.8696, Recall: 0.7940\n",
      "Starting epoch 15/40...\n",
      "Epoch [15/40], Loss: 0.1601, Accuracy: 0.7565, F1 Score: 0.8468, Precision: 0.8808, Recall: 0.8176\n",
      "Starting epoch 16/40...\n",
      "Epoch [16/40], Loss: 0.1411, Accuracy: 0.7789, F1 Score: 0.8638, Precision: 0.8913, Recall: 0.8398\n",
      "Starting epoch 17/40...\n",
      "Epoch [17/40], Loss: 0.1235, Accuracy: 0.8009, F1 Score: 0.8804, Precision: 0.9037, Recall: 0.8594\n",
      "Starting epoch 18/40...\n",
      "Epoch [18/40], Loss: 0.1101, Accuracy: 0.8218, F1 Score: 0.8945, Precision: 0.9128, Recall: 0.8778\n",
      "Starting epoch 19/40...\n",
      "Epoch [19/40], Loss: 0.0976, Accuracy: 0.8397, F1 Score: 0.9072, Precision: 0.9231, Recall: 0.8924\n",
      "Starting epoch 20/40...\n",
      "Epoch [20/40], Loss: 0.0871, Accuracy: 0.8550, F1 Score: 0.9175, Precision: 0.9313, Recall: 0.9045\n",
      "Starting epoch 21/40...\n",
      "Epoch [21/40], Loss: 0.0803, Accuracy: 0.8662, F1 Score: 0.9252, Precision: 0.9363, Recall: 0.9146\n",
      "Starting epoch 22/40...\n",
      "Epoch [22/40], Loss: 0.0748, Accuracy: 0.8748, F1 Score: 0.9309, Precision: 0.9408, Recall: 0.9213\n",
      "Starting epoch 23/40...\n",
      "Epoch [23/40], Loss: 0.0667, Accuracy: 0.8881, F1 Score: 0.9391, Precision: 0.9474, Recall: 0.9311\n",
      "Starting epoch 24/40...\n",
      "Epoch [24/40], Loss: 0.0616, Accuracy: 0.8989, F1 Score: 0.9456, Precision: 0.9531, Recall: 0.9383\n",
      "Starting epoch 25/40...\n",
      "Epoch [25/40], Loss: 0.0586, Accuracy: 0.9042, F1 Score: 0.9489, Precision: 0.9556, Recall: 0.9424\n",
      "Starting epoch 26/40...\n",
      "Epoch [26/40], Loss: 0.0538, Accuracy: 0.9114, F1 Score: 0.9527, Precision: 0.9586, Recall: 0.9470\n",
      "Starting epoch 27/40...\n",
      "Epoch [27/40], Loss: 0.0531, Accuracy: 0.9138, F1 Score: 0.9541, Precision: 0.9592, Recall: 0.9491\n",
      "Starting epoch 28/40...\n",
      "Epoch [28/40], Loss: 0.0511, Accuracy: 0.9162, F1 Score: 0.9555, Precision: 0.9610, Recall: 0.9501\n",
      "Starting epoch 29/40...\n",
      "Epoch [29/40], Loss: 0.0480, Accuracy: 0.9217, F1 Score: 0.9602, Precision: 0.9654, Recall: 0.9552\n",
      "Starting epoch 30/40...\n",
      "Epoch [30/40], Loss: 0.0428, Accuracy: 0.9279, F1 Score: 0.9625, Precision: 0.9662, Recall: 0.9588\n",
      "Starting epoch 31/40...\n",
      "Epoch [31/40], Loss: 0.0452, Accuracy: 0.9246, F1 Score: 0.9620, Precision: 0.9664, Recall: 0.9577\n",
      "Starting epoch 32/40...\n",
      "Epoch [32/40], Loss: 0.0406, Accuracy: 0.9337, F1 Score: 0.9665, Precision: 0.9686, Recall: 0.9643\n",
      "Starting epoch 33/40...\n",
      "Epoch [33/40], Loss: 0.0386, Accuracy: 0.9378, F1 Score: 0.9682, Precision: 0.9712, Recall: 0.9653\n",
      "Starting epoch 34/40...\n",
      "Epoch [34/40], Loss: 0.0414, Accuracy: 0.9306, F1 Score: 0.9645, Precision: 0.9682, Recall: 0.9608\n",
      "Starting epoch 35/40...\n",
      "Epoch [35/40], Loss: 0.0363, Accuracy: 0.9410, F1 Score: 0.9697, Precision: 0.9728, Recall: 0.9666\n",
      "Starting epoch 36/40...\n",
      "Epoch [36/40], Loss: 0.0361, Accuracy: 0.9411, F1 Score: 0.9701, Precision: 0.9732, Recall: 0.9670\n",
      "Starting epoch 37/40...\n",
      "Epoch [37/40], Loss: 0.0356, Accuracy: 0.9409, F1 Score: 0.9703, Precision: 0.9728, Recall: 0.9677\n",
      "Starting epoch 38/40...\n",
      "Epoch [38/40], Loss: 0.0344, Accuracy: 0.9429, F1 Score: 0.9715, Precision: 0.9742, Recall: 0.9688\n",
      "Starting epoch 39/40...\n",
      "Epoch [39/40], Loss: 0.0312, Accuracy: 0.9452, F1 Score: 0.9728, Precision: 0.9763, Recall: 0.9693\n",
      "Starting epoch 40/40...\n",
      "Epoch [40/40], Loss: 0.0334, Accuracy: 0.9441, F1 Score: 0.9721, Precision: 0.9745, Recall: 0.9696\n",
      "EfficientNetV2 training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "model = efficientnet_v2_s(pretrained=True)\n",
    "num_classes = y_train_bin.shape[1]  \n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=40, patience=3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        precision = precision_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        recall = recall_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "print('Training EfficientNetV2...')\n",
    "train_model(model, dataloader)\n",
    "print('EfficientNetV2 training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConVNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ConvNeXt...\n",
      "Starting epoch 1/40...\n",
      "Epoch [1/40], Loss: 0.5492, Accuracy: 0.0328, F1 Score: 0.0282, Precision: 0.2657, Recall: 0.0165\n",
      "Starting epoch 2/40...\n",
      "Epoch [2/40], Loss: 0.5468, Accuracy: 0.0163, F1 Score: 0.0153, Precision: 0.2415, Recall: 0.0083\n",
      "Starting epoch 3/40...\n",
      "Epoch [3/40], Loss: 0.5464, Accuracy: 0.0023, F1 Score: 0.0023, Precision: 0.1444, Recall: 0.0012\n",
      "Starting epoch 4/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40], Loss: 0.5459, Accuracy: 0.0039, F1 Score: 0.0036, Precision: 0.0897, Recall: 0.0018\n",
      "Starting epoch 5/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40], Loss: 0.5461, Accuracy: 0.0004, F1 Score: 0.0003, Precision: 0.0706, Recall: 0.0002\n",
      "Starting epoch 6/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40], Loss: 0.5459, Accuracy: 0.0001, F1 Score: 0.0003, Precision: 0.2000, Recall: 0.0002\n",
      "Starting epoch 7/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40], Loss: 0.5458, Accuracy: 0.0002, F1 Score: 0.0002, Precision: 0.1333, Recall: 0.0001\n",
      "Starting epoch 8/40...\n",
      "Epoch [8/40], Loss: 0.5458, Accuracy: 0.0001, F1 Score: 0.0008, Precision: 0.3500, Recall: 0.0004\n",
      "Starting epoch 9/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40], Loss: 0.5458, Accuracy: 0.0001, F1 Score: 0.0001, Precision: 0.1000, Recall: 0.0000\n",
      "Starting epoch 10/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], Loss: 0.5457, Accuracy: 0.0001, F1 Score: 0.0002, Precision: 0.2000, Recall: 0.0001\n",
      "Starting epoch 11/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40], Loss: 0.5458, Accuracy: 0.0011, F1 Score: 0.0010, Precision: 0.2720, Recall: 0.0005\n",
      "Starting epoch 12/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40], Loss: 0.5456, Accuracy: 0.0001, F1 Score: 0.0001, Precision: 0.0800, Recall: 0.0001\n",
      "Starting epoch 13/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40], Loss: 0.5457, Accuracy: 0.0000, F1 Score: 0.0000, Precision: 0.0000, Recall: 0.0000\n",
      "Starting epoch 14/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40], Loss: 0.5456, Accuracy: 0.0000, F1 Score: 0.0000, Precision: 0.0000, Recall: 0.0000\n",
      "Starting epoch 15/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40], Loss: 0.5456, Accuracy: 0.0044, F1 Score: 0.0042, Precision: 0.1964, Recall: 0.0022\n",
      "Starting epoch 16/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40], Loss: 0.5455, Accuracy: 0.0000, F1 Score: 0.0000, Precision: 0.0000, Recall: 0.0000\n",
      "Starting epoch 17/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40], Loss: 0.5456, Accuracy: 0.0001, F1 Score: 0.0001, Precision: 0.2000, Recall: 0.0001\n",
      "Starting epoch 18/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40], Loss: 0.5455, Accuracy: 0.0009, F1 Score: 0.0008, Precision: 0.0780, Recall: 0.0004\n",
      "Starting epoch 19/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40], Loss: 0.5456, Accuracy: 0.0001, F1 Score: 0.0001, Precision: 0.1000, Recall: 0.0001\n",
      "Starting epoch 20/40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40], Loss: 0.5455, Accuracy: 0.0025, F1 Score: 0.0024, Precision: 0.2193, Recall: 0.0012\n",
      "Starting epoch 21/40...\n",
      "Epoch [21/40], Loss: 0.5456, Accuracy: 0.0001, F1 Score: 0.0001, Precision: 0.0500, Recall: 0.0000\n",
      "Early stopping triggered after 21 epochs.\n",
      "ConvNeXt training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/dissc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torchvision import transforms\n",
    "from torchvision.models import convnext_tiny\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = convnext_tiny(pretrained=True)\n",
    "num_classes = y_train_bin.shape[1] \n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)), \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=40, patience=3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        precision = precision_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        recall = recall_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "print('Training ConvNeXt...')\n",
    "train_model(model, dataloader)\n",
    "print('ConvNeXt training completed.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
