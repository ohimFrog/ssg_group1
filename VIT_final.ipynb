{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1tVYWwYvJRn"
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nh5y8rXFwxuv",
    "outputId": "33b932b9-159c-4972-ec64-83e7e20ced28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wfdb in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (4.1.2)\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (0.12.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.10.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.8.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gaya/.local/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gaya/.local/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (2024.8.30)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from SoundFile>=0.10.0->wfdb) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdW9WGzavJRr",
    "outputId": "35f2eba1-aa4f-406c-f830-8f7b725953f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (17084, 1000, 12), Labels: (17084, 5)\n",
      "Validation Data Shape: (2146, 1000, 12), Labels: (2146, 5)\n",
      "Test Data Shape: (2158, 1000, 12), Labels: (2158, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    \"\"\"df.index를 기준으로 데이터를 로드\"\"\"\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_lr']]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_hr']]\n",
    "    # df.index에 있는 데이터만 로드\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "# 데이터 경로 설정\n",
    "path = \"./\"\n",
    "sampling_rate = 100\n",
    "\n",
    "# PTB-XL 데이터베이스 로드\n",
    "df = pd.read_csv(os.path.join(path, 'ptbxl_database.csv'), index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# 진단 정보 로드\n",
    "agg_df = pd.read_csv(os.path.join(path, 'scp_statements.csv'), index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    \"\"\"진단 클래스를 매핑하는 함수\"\"\"\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# 진단 클래스 매핑\n",
    "df['diagnostic_superclass'] = df.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# 빈 클래스 제거\n",
    "df = df[df['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Raw data 로드\n",
    "X = load_raw_data(df, sampling_rate, path)\n",
    "\n",
    "# 크기 확인\n",
    "assert len(X) == len(df), \"X와 df의 크기가 일치하지 않습니다.\"\n",
    "\n",
    "# 데이터셋 분리\n",
    "test_fold = 10\n",
    "val_fold = 9\n",
    "\n",
    "train_filter = (df.strat_fold != test_fold) & (df.strat_fold != val_fold)\n",
    "val_filter = df.strat_fold == val_fold\n",
    "test_filter = df.strat_fold == test_fold\n",
    "\n",
    "X_train = X[train_filter]\n",
    "y_train = list(df[train_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_val = X[val_filter]\n",
    "y_val = list(df[val_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_test = X[test_filter]\n",
    "y_test = list(df[test_filter]['diagnostic_superclass'])\n",
    "\n",
    "# 다중 라벨 이진화\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Labels: {y_train_bin.shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}, Labels: {y_val_bin.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}, Labels: {y_test_bin.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjkSOnjjvJRs"
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsrXZlmBvJRs",
    "outputId": "a54cb93a-96ff-428e-ff4f-dd0a73a4863b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, DeiTForImageClassification\n",
    "from torchvision.models import convnext_tiny, efficientnet_v2_s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Custom Dataset for ECG Data\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            # ECG 데이터를 3채널로 확장\n",
    "            sample = self.transform(sample)\n",
    "        return sample.float(), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Numpy 배열 -> Tensor\n",
    "    transforms.Resize((182, 256)),  # 이미지 크기 조정\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),  # 1채널 데이터를 3채널로 확장\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = ECGDataset(X_train, y_train_bin, transform=transform)\n",
    "val_dataset = ECGDataset(X_val, y_val_bin, transform=transform)\n",
    "test_dataset = ECGDataset(X_test, y_test_bin, transform=transform)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 확인\n",
    "class_names = mlb.classes_\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mz24GEjNvJRs",
    "outputId": "693a81e9-8b6e-41f2-ce62-4b06d87040a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP-_KN4tEYsg"
   },
   "source": [
    "### VIT 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sR7dOl7DEX34"
   },
   "outputs": [],
   "source": [
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, dropout=0.1):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return x\n",
    "\n",
    "class ViTBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, hidden_dim, dropout=0.1):\n",
    "        super(ViTBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = MLPBlock(embed_dim, hidden_dim, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attn(x, x, x)\n",
    "        x = self.dropout(x) + x_res\n",
    "\n",
    "        x_res = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.dropout(x) + x_res\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels, num_classes, embed_dim, depth, num_heads, hidden_dim, dropout=0.1):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = (image_size[0] // patch_size[0]) * (image_size[1] // patch_size[1])\n",
    "\n",
    "        self.patch_embed = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, self.num_patches, embed_dim))\n",
    "\n",
    "        self.transformer = nn.ModuleList([\n",
    "            ViTBlock(embed_dim, num_heads, hidden_dim, dropout=dropout) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = x + self.pos_embedding\n",
    "\n",
    "        for block in self.transformer:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HFTq-MApoIKR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import torch\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=None,\n",
    "    num_epochs=40,\n",
    "    patience=3,\n",
    "    learning_rate=0.001,\n",
    "    checkpoint_path='vit_checkpoint.pth'\n",
    "):\n",
    "    \"\"\"Vision Transformer 모델 학습 함수.\n",
    "\n",
    "    Args:\n",
    "        model: 학습할 PyTorch 모델.\n",
    "        train_loader: 학습 데이터용 DataLoader.\n",
    "        val_loader: 검증 데이터용 DataLoader (선택).\n",
    "        num_epochs: 학습할 epoch 수.\n",
    "        patience: 조기 종료를 위한 patience.\n",
    "        learning_rate: 옵티마이저 학습률.\n",
    "        checkpoint_path: 체크포인트 저장 경로.\n",
    "\n",
    "    Returns:\n",
    "        dict: 학습 로그 (손실, 정확도 등).\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 학습 상태 초기화\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    logs = {'train_loss': [], 'train_accuracy': [], 'train_f1': []}\n",
    "\n",
    "    if val_loader:\n",
    "        logs['val_loss'] = []\n",
    "        logs['val_accuracy'] = []\n",
    "        logs['val_f1'] = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        # Training loop\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)  # 모델 forward\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "        # Train metrics\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "        logs['train_loss'].append(epoch_loss)\n",
    "        logs['train_accuracy'].append(accuracy)\n",
    "        logs['train_f1'].append(f1)\n",
    "\n",
    "        # Validation loop (if provided)\n",
    "        if val_loader:\n",
    "            val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, criterion)\n",
    "            logs['val_loss'].append(val_loss)\n",
    "            logs['val_accuracy'].append(val_accuracy)\n",
    "            logs['val_f1'].append(val_f1)\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "        # Checkpoint and early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Best model 로드\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"Best model loaded.\")\n",
    "    return logs\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    \"\"\"모델 검증 및 평가.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "    f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "\n",
    "    return epoch_loss, accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9GRaAuaaFK6A",
    "outputId": "4a9e9510-a1b1-4499-ad7e-020f2006a38e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 5])\n",
      "Training ViT...\n",
      "Starting epoch 1/40...\n",
      "Epoch 1, Train Loss: 0.5289, Accuracy: 0.1725, F1 Score: 0.1448\n",
      "Epoch 1, Val Loss: 0.5000, Val Accuracy: 0.2665, Val F1: 0.2122\n",
      "Checkpoint saved at epoch 1.\n",
      "Starting epoch 2/40...\n",
      "Epoch 2, Train Loss: 0.4654, Accuracy: 0.3307, F1 Score: 0.3095\n",
      "Epoch 2, Val Loss: 0.4296, Val Accuracy: 0.3798, Val F1: 0.4090\n",
      "Checkpoint saved at epoch 2.\n",
      "Starting epoch 3/40...\n",
      "Epoch 3, Train Loss: 0.4271, Accuracy: 0.3773, F1 Score: 0.4135\n",
      "Epoch 3, Val Loss: 0.4145, Val Accuracy: 0.3910, Val F1: 0.4538\n",
      "Checkpoint saved at epoch 3.\n",
      "Starting epoch 4/40...\n",
      "Epoch 4, Train Loss: 0.4082, Accuracy: 0.4040, F1 Score: 0.4668\n",
      "Epoch 4, Val Loss: 0.3984, Val Accuracy: 0.4450, Val F1: 0.4675\n",
      "Checkpoint saved at epoch 4.\n",
      "Starting epoch 5/40...\n",
      "Epoch 5, Train Loss: 0.3994, Accuracy: 0.4251, F1 Score: 0.5033\n",
      "Epoch 5, Val Loss: 0.3971, Val Accuracy: 0.4613, Val F1: 0.5160\n",
      "Checkpoint saved at epoch 5.\n",
      "Starting epoch 6/40...\n",
      "Epoch 6, Train Loss: 0.3890, Accuracy: 0.4370, F1 Score: 0.5296\n",
      "Epoch 6, Val Loss: 0.3800, Val Accuracy: 0.4683, Val F1: 0.5360\n",
      "Checkpoint saved at epoch 6.\n",
      "Starting epoch 7/40...\n",
      "Epoch 7, Train Loss: 0.3808, Accuracy: 0.4563, F1 Score: 0.5541\n",
      "Epoch 7, Val Loss: 0.3757, Val Accuracy: 0.4870, Val F1: 0.5148\n",
      "Checkpoint saved at epoch 7.\n",
      "Starting epoch 8/40...\n",
      "Epoch 8, Train Loss: 0.3746, Accuracy: 0.4634, F1 Score: 0.5654\n",
      "Epoch 8, Val Loss: 0.3783, Val Accuracy: 0.4790, Val F1: 0.5502\n",
      "Checkpoint saved at epoch 8.\n",
      "Starting epoch 9/40...\n",
      "Epoch 9, Train Loss: 0.3654, Accuracy: 0.4741, F1 Score: 0.5779\n",
      "Epoch 9, Val Loss: 0.3781, Val Accuracy: 0.4939, Val F1: 0.5637\n",
      "Checkpoint saved at epoch 9.\n",
      "Starting epoch 10/40...\n",
      "Epoch 10, Train Loss: 0.3609, Accuracy: 0.4838, F1 Score: 0.5907\n",
      "Epoch 10, Val Loss: 0.3771, Val Accuracy: 0.4884, Val F1: 0.6011\n",
      "Checkpoint saved at epoch 10.\n",
      "Starting epoch 11/40...\n",
      "Epoch 11, Train Loss: 0.3565, Accuracy: 0.4909, F1 Score: 0.6011\n",
      "Epoch 11, Val Loss: 0.3667, Val Accuracy: 0.4539, Val F1: 0.6086\n",
      "Checkpoint saved at epoch 11.\n",
      "Starting epoch 12/40...\n",
      "Epoch 12, Train Loss: 0.3516, Accuracy: 0.4973, F1 Score: 0.6100\n",
      "Epoch 12, Val Loss: 0.3749, Val Accuracy: 0.5196, Val F1: 0.5725\n",
      "Checkpoint saved at epoch 12.\n",
      "Starting epoch 13/40...\n",
      "Epoch 13, Train Loss: 0.3476, Accuracy: 0.5040, F1 Score: 0.6132\n",
      "Epoch 13, Val Loss: 0.3609, Val Accuracy: 0.4930, Val F1: 0.6063\n",
      "Checkpoint saved at epoch 13.\n",
      "Starting epoch 14/40...\n",
      "Epoch 14, Train Loss: 0.3433, Accuracy: 0.5115, F1 Score: 0.6239\n",
      "Epoch 14, Val Loss: 0.3713, Val Accuracy: 0.5070, Val F1: 0.5876\n",
      "Checkpoint saved at epoch 14.\n",
      "Starting epoch 15/40...\n",
      "Epoch 15, Train Loss: 0.3395, Accuracy: 0.5174, F1 Score: 0.6300\n",
      "Epoch 15, Val Loss: 0.3569, Val Accuracy: 0.5233, Val F1: 0.6198\n",
      "Checkpoint saved at epoch 15.\n",
      "Starting epoch 16/40...\n",
      "Epoch 16, Train Loss: 0.3362, Accuracy: 0.5189, F1 Score: 0.6350\n",
      "Epoch 16, Val Loss: 0.3451, Val Accuracy: 0.5172, Val F1: 0.6319\n",
      "Checkpoint saved at epoch 16.\n",
      "Starting epoch 17/40...\n",
      "Epoch 17, Train Loss: 0.3339, Accuracy: 0.5215, F1 Score: 0.6370\n",
      "Epoch 17, Val Loss: 0.3427, Val Accuracy: 0.5238, Val F1: 0.6364\n",
      "Checkpoint saved at epoch 17.\n",
      "Starting epoch 18/40...\n",
      "Epoch 18, Train Loss: 0.3309, Accuracy: 0.5277, F1 Score: 0.6462\n",
      "Epoch 18, Val Loss: 0.3413, Val Accuracy: 0.5340, Val F1: 0.6532\n",
      "Checkpoint saved at epoch 18.\n",
      "Starting epoch 19/40...\n",
      "Epoch 19, Train Loss: 0.3279, Accuracy: 0.5341, F1 Score: 0.6491\n",
      "Epoch 19, Val Loss: 0.3435, Val Accuracy: 0.5126, Val F1: 0.6690\n",
      "Checkpoint saved at epoch 19.\n",
      "Starting epoch 20/40...\n",
      "Epoch 20, Train Loss: 0.3260, Accuracy: 0.5357, F1 Score: 0.6531\n",
      "Epoch 20, Val Loss: 0.3484, Val Accuracy: 0.4935, Val F1: 0.6372\n",
      "Checkpoint saved at epoch 20.\n",
      "Starting epoch 21/40...\n",
      "Epoch 21, Train Loss: 0.3240, Accuracy: 0.5345, F1 Score: 0.6512\n",
      "Epoch 21, Val Loss: 0.3456, Val Accuracy: 0.5140, Val F1: 0.6245\n",
      "Checkpoint saved at epoch 21.\n",
      "Starting epoch 22/40...\n",
      "Epoch 22, Train Loss: 0.3209, Accuracy: 0.5388, F1 Score: 0.6570\n",
      "Epoch 22, Val Loss: 0.3374, Val Accuracy: 0.5308, Val F1: 0.6430\n",
      "Checkpoint saved at epoch 22.\n",
      "Starting epoch 23/40...\n",
      "Epoch 23, Train Loss: 0.3201, Accuracy: 0.5419, F1 Score: 0.6601\n",
      "Epoch 23, Val Loss: 0.3367, Val Accuracy: 0.5331, Val F1: 0.6332\n",
      "Checkpoint saved at epoch 23.\n",
      "Starting epoch 24/40...\n",
      "Epoch 24, Train Loss: 0.3189, Accuracy: 0.5417, F1 Score: 0.6613\n",
      "Epoch 24, Val Loss: 0.3494, Val Accuracy: 0.5349, Val F1: 0.6192\n",
      "Checkpoint saved at epoch 24.\n",
      "Starting epoch 25/40...\n",
      "Epoch 25, Train Loss: 0.3162, Accuracy: 0.5448, F1 Score: 0.6637\n",
      "Epoch 25, Val Loss: 0.3439, Val Accuracy: 0.5424, Val F1: 0.6550\n",
      "Checkpoint saved at epoch 25.\n",
      "Starting epoch 26/40...\n",
      "Epoch 26, Train Loss: 0.3144, Accuracy: 0.5517, F1 Score: 0.6694\n",
      "Epoch 26, Val Loss: 0.3416, Val Accuracy: 0.5252, Val F1: 0.6131\n",
      "Checkpoint saved at epoch 26.\n",
      "Starting epoch 27/40...\n",
      "Epoch 27, Train Loss: 0.3130, Accuracy: 0.5482, F1 Score: 0.6678\n",
      "Epoch 27, Val Loss: 0.3359, Val Accuracy: 0.5294, Val F1: 0.6239\n",
      "Checkpoint saved at epoch 27.\n",
      "Starting epoch 28/40...\n",
      "Epoch 28, Train Loss: 0.3116, Accuracy: 0.5566, F1 Score: 0.6736\n",
      "Epoch 28, Val Loss: 0.3338, Val Accuracy: 0.5382, Val F1: 0.6254\n",
      "Checkpoint saved at epoch 28.\n",
      "Starting epoch 29/40...\n",
      "Epoch 29, Train Loss: 0.3107, Accuracy: 0.5534, F1 Score: 0.6724\n",
      "Epoch 29, Val Loss: 0.3340, Val Accuracy: 0.5471, Val F1: 0.6634\n",
      "Checkpoint saved at epoch 29.\n",
      "Starting epoch 30/40...\n",
      "Epoch 30, Train Loss: 0.3084, Accuracy: 0.5544, F1 Score: 0.6763\n",
      "Epoch 30, Val Loss: 0.3449, Val Accuracy: 0.5368, Val F1: 0.6383\n",
      "Checkpoint saved at epoch 30.\n",
      "Starting epoch 31/40...\n",
      "Epoch 31, Train Loss: 0.3071, Accuracy: 0.5617, F1 Score: 0.6813\n",
      "Epoch 31, Val Loss: 0.3446, Val Accuracy: 0.5480, Val F1: 0.6113\n",
      "Checkpoint saved at epoch 31.\n",
      "Starting epoch 32/40...\n",
      "Epoch 32, Train Loss: 0.3055, Accuracy: 0.5618, F1 Score: 0.6801\n",
      "Epoch 32, Val Loss: 0.3330, Val Accuracy: 0.5568, Val F1: 0.6671\n",
      "Checkpoint saved at epoch 32.\n",
      "Starting epoch 33/40...\n",
      "Epoch 33, Train Loss: 0.3048, Accuracy: 0.5662, F1 Score: 0.6829\n",
      "Epoch 33, Val Loss: 0.3346, Val Accuracy: 0.5494, Val F1: 0.6455\n",
      "Checkpoint saved at epoch 33.\n",
      "Starting epoch 34/40...\n",
      "Epoch 34, Train Loss: 0.3026, Accuracy: 0.5651, F1 Score: 0.6839\n",
      "Epoch 34, Val Loss: 0.3355, Val Accuracy: 0.5210, Val F1: 0.6252\n",
      "Checkpoint saved at epoch 34.\n",
      "Starting epoch 35/40...\n",
      "Epoch 35, Train Loss: 0.3020, Accuracy: 0.5677, F1 Score: 0.6859\n",
      "Epoch 35, Val Loss: 0.3398, Val Accuracy: 0.5284, Val F1: 0.6293\n",
      "Checkpoint saved at epoch 35.\n",
      "Starting epoch 36/40...\n",
      "Epoch 36, Train Loss: 0.2997, Accuracy: 0.5685, F1 Score: 0.6866\n",
      "Epoch 36, Val Loss: 0.3299, Val Accuracy: 0.5480, Val F1: 0.6442\n",
      "Checkpoint saved at epoch 36.\n",
      "Starting epoch 37/40...\n",
      "Epoch 37, Train Loss: 0.2990, Accuracy: 0.5686, F1 Score: 0.6881\n",
      "Epoch 37, Val Loss: 0.3362, Val Accuracy: 0.5485, Val F1: 0.6463\n",
      "Checkpoint saved at epoch 37.\n",
      "Starting epoch 38/40...\n",
      "Epoch 38, Train Loss: 0.2978, Accuracy: 0.5721, F1 Score: 0.6908\n",
      "Epoch 38, Val Loss: 0.3392, Val Accuracy: 0.5517, Val F1: 0.6447\n",
      "Checkpoint saved at epoch 38.\n",
      "Starting epoch 39/40...\n",
      "Epoch 39, Train Loss: 0.2967, Accuracy: 0.5738, F1 Score: 0.6937\n",
      "Epoch 39, Val Loss: 0.3393, Val Accuracy: 0.5573, Val F1: 0.6478\n",
      "Checkpoint saved at epoch 39.\n",
      "Starting epoch 40/40...\n",
      "Epoch 40, Train Loss: 0.2961, Accuracy: 0.5753, F1 Score: 0.6947\n",
      "Epoch 40, Val Loss: 0.3423, Val Accuracy: 0.5475, Val F1: 0.6340\n",
      "Checkpoint saved at epoch 40.\n",
      "Best model loaded.\n",
      "ViT training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4175860/503500460.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    }
   ],
   "source": [
    "# VisionTransformer 모델 초기화\n",
    "vit_model = VisionTransformer(\n",
    "    image_size=(182, 256),  # 데이터 크기\n",
    "    patch_size=(8, 8),      # 최적 패치 크기\n",
    "    in_channels=3,          # 입력 채널 수 (3채널 데이터 사용)\n",
    "    num_classes=y_train_bin.shape[1],  # 클래스 수\n",
    "    embed_dim=256,          # 최적 임베딩 차원\n",
    "    depth=6,                # 최적 Transformer 블록 깊이\n",
    "    num_heads=256 // 64,    # Multi-head Attention 헤드 수 (임베딩 차원 나누기 64)\n",
    "    hidden_dim=256 * 4,     # MLP hidden layer 차원\n",
    "    dropout=0.1             # 최적 Dropout 비율\n",
    ")\n",
    "vit_model = vit_model.to(device)\n",
    "\n",
    "# 모델 출력 확인 (가상 데이터)\n",
    "dummy_input = torch.randn(16, 3, 182, 256).to(device)  # 가상 입력 데이터 생성\n",
    "output = vit_model(dummy_input)  # 모델 출력 확인\n",
    "print(f\"Output shape: {output.shape}\")  # Expected: (16, num_classes)\n",
    "\n",
    "# 학습 루프 실행\n",
    "print('Training ViT...')\n",
    "logs = train_model(\n",
    "    model=vit_model,\n",
    "    train_loader=train_loader,  # 제공된 학습 데이터 로더\n",
    "    val_loader=val_loader,      # 제공된 검증 데이터 로더\n",
    "    num_epochs=40,              # 총 학습 epoch 수\n",
    "    patience=5,                 # 조기 종료를 위한 patience\n",
    "    learning_rate=0.0001,       # 최적 학습률\n",
    "    checkpoint_path='best_vit_model.pth'  # 체크포인트 저장 경로\n",
    ")\n",
    "print('ViT training completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imI4K1iuXtZQ",
    "outputId": "7c738de5-2c67-48de-c266-d68a1af43d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Loss: 0.3489\n",
      "Validation Accuracy: 0.5405\n",
      "Validation F1 Score: 0.6166\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.3563\n",
      "Test Accuracy: 0.5431\n",
      "Test F1 Score: 0.6141\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 평가\n",
    "validation_loader = DataLoader(\n",
    "    ECGDataset(X_val, y_val_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_loss, val_accuracy, val_f1 = evaluate_model(vit_model, validation_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_loader = DataLoader(\n",
    "    ECGDataset(X_test, y_test_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_accuracy, test_f1 = evaluate_model(vit_model, test_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "group4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
