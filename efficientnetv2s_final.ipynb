{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\home\\anaconda3\\lib\\site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\home\\anaconda3\\lib\\site-packages (0.20.1+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\home\\anaconda3\\lib\\site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\home\\anaconda3\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # 에포크 진행 상황 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wfdb in c:\\users\\home\\anaconda3\\lib\\site-packages (4.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (0.12.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.10.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.8.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from wfdb) (1.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\home\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->wfdb) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\home\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->wfdb) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (2023.11.17)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from SoundFile>=0.10.0->wfdb) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\home\\anaconda3\\lib\\site-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\home\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (17084, 1000, 12), Labels: (17084, 5)\n",
      "Validation Data Shape: (2146, 1000, 12), Labels: (2146, 5)\n",
      "Test Data Shape: (2158, 1000, 12), Labels: (2158, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    \"\"\"df.index를 기준으로 데이터를 로드\"\"\"\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_lr']]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_hr']]\n",
    "    # df.index에 있는 데이터만 로드\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "# 데이터 경로 설정\n",
    "path = \"D:\\ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n",
    "sampling_rate = 100\n",
    "\n",
    "# PTB-XL 데이터베이스 로드\n",
    "df = pd.read_csv(os.path.join(path, 'ptbxl_database.csv'), index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# 진단 정보 로드\n",
    "agg_df = pd.read_csv(os.path.join(path, 'scp_statements.csv'), index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    \"\"\"진단 클래스를 매핑하는 함수\"\"\"\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# 진단 클래스 매핑\n",
    "df['diagnostic_superclass'] = df.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# 빈 클래스 제거\n",
    "df = df[df['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Raw data 로드\n",
    "X = load_raw_data(df, sampling_rate, path)\n",
    "\n",
    "# 크기 확인\n",
    "assert len(X) == len(df), \"X와 df의 크기가 일치하지 않습니다.\"\n",
    "\n",
    "# 데이터셋 분리\n",
    "test_fold = 10\n",
    "val_fold = 9\n",
    "\n",
    "train_filter = (df.strat_fold != test_fold) & (df.strat_fold != val_fold)\n",
    "val_filter = df.strat_fold == val_fold\n",
    "test_filter = df.strat_fold == test_fold\n",
    "\n",
    "X_train = X[train_filter]\n",
    "y_train = list(df[train_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_val = X[val_filter]\n",
    "y_val = list(df[val_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_test = X[test_filter]\n",
    "y_test = list(df[test_filter]['diagnostic_superclass'])\n",
    "\n",
    "# 다중 라벨 이진화\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Labels: {y_train_bin.shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}, Labels: {y_val_bin.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}, Labels: {y_test_bin.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Custom Dataset for ECG Data\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            # ECG 데이터를 3채널로 확장\n",
    "            sample = self.transform(sample)\n",
    "        return sample.float(), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Numpy 배열 -> Tensor\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),  # 1채널 데이터를 3채널로 확장\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = ECGDataset(X_train, y_train_bin, transform=transform)\n",
    "val_dataset = ECGDataset(X_val, y_val_bin, transform=transform)\n",
    "test_dataset = ECGDataset(X_test, y_test_bin, transform=transform)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 확인\n",
    "class_names = mlb.classes_\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficientnetv2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Callable, Optional, List\n",
    "from functools import partial\n",
    "\n",
    "# Conv2dNormActivation: Convolution + Normalization + Activation\n",
    "class Conv2dNormActivation(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, groups=1, norm_layer=None, activation_layer=None):\n",
    "        super(Conv2dNormActivation, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, groups=groups, padding=kernel_size // 2) # 2D Convolution\n",
    "        self.norm = norm_layer(out_channels) if norm_layer else nn.Identity() # 정규화 레이어\n",
    "        self.activation = activation_layer() if activation_layer else nn.Identity() # 활성화 함수\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activation(self.norm(self.conv(x))) # 순차적으로 실행\n",
    "\n",
    "\n",
    "# Squeeze and Excitation Block\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, squeeze_channels, activation=nn.SiLU):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels, squeeze_channels, 1) # 1x1 Convolution으로 채널 수 축소\n",
    "        self.activation = activation() # 활성화 함수\n",
    "        self.fc2 = nn.Conv2d(squeeze_channels, in_channels, 1) # 1x1 Convolution으로 채널 수 복원\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid로 중요도 계산\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x * self.sigmoid(self.fc2(self.activation(self.fc1(x)))) # 중요도를 입력 특징에 반영\n",
    "\n",
    "\n",
    "# Stochastic Depth\n",
    "class StochasticDepth(nn.Module):\n",
    "    def __init__(self, drop_prob: float, mode: str):\n",
    "        super(StochasticDepth, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.drop_prob > 0:\n",
    "            if self.training:\n",
    "                keep_prob = 1 - self.drop_prob\n",
    "                mask = torch.bernoulli(torch.full((x.size(0),), keep_prob)).to(x.device).view(-1, 1, 1, 1)\n",
    "                return x * mask / keep_prob # 드롭아웃 적용\n",
    "            return x\n",
    "        return x\n",
    "\n",
    "# _MBConvConfig: Mobile Bottleneck Block의 설정 정보를 저장하는 클래스\n",
    "class _MBConvConfig:\n",
    "    def __init__(self, expand_ratio: float, kernel: int, stride: int, input_channels: int, out_channels: int, num_layers: int, block: Callable[..., nn.Module]):\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.kernel = kernel # 커널 크기\n",
    "        self.stride = stride # 스트라이드 크기\n",
    "        self.input_channels = input_channels # 입력 채널 수\n",
    "        self.out_channels = out_channels # 출력 채널 수\n",
    "        self.num_layers = num_layers # 레이어 반복 횟수\n",
    "        self.block = block # 블록 클래스\n",
    "\n",
    "    # 채널 수를 조정하여 8로 나누어떨어지게 만드는 유틸리티 함수\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_mult: float, min_value: Optional[int] = None) -> int:\n",
    "        return _make_divisible(channels * width_mult, 8, min_value)\n",
    "\n",
    "\n",
    "class MBConvConfig(_MBConvConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        expand_ratio: float,\n",
    "        kernel: int,\n",
    "        stride: int,\n",
    "        input_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        width_mult: float = 1.0,\n",
    "        depth_mult: float = 1.0,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        input_channels = self.adjust_channels(input_channels, width_mult)\n",
    "        out_channels = self.adjust_channels(out_channels, width_mult)\n",
    "        num_layers = self.adjust_depth(num_layers, depth_mult)\n",
    "        if block is None:\n",
    "            block = MBConv\n",
    "        super().__init__(expand_ratio, kernel, stride, input_channels, out_channels, num_layers, block)\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_depth(num_layers: int, depth_mult: float):\n",
    "        return int(math.ceil(num_layers * depth_mult))\n",
    "\n",
    "\n",
    "class FusedMBConvConfig(_MBConvConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        expand_ratio: float,\n",
    "        kernel: int,\n",
    "        stride: int,\n",
    "        input_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        if block is None:\n",
    "            block = FusedMBConv\n",
    "        super().__init__(expand_ratio, kernel, stride, input_channels, out_channels, num_layers, block)\n",
    "\n",
    "\n",
    "\n",
    "# MBConv 블록 구현 (# MBConv 블록 구현 (Mobile Inverted Bottleneck Convolution 블록))\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, cnf: _MBConvConfig, stochastic_depth_prob: float, norm_layer: Callable[..., nn.Module], se_layer: Callable[..., nn.Module] = SqueezeExcitation) -> None:\n",
    "        super(MBConv, self).__init__()\n",
    "\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError(\"illegal stride value\") # 스트라이드 값은 1 또는 2만 허용\n",
    "\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.SiLU # 기본 활성화 함수\n",
    "\n",
    "        # Expand: 1x1 conv, 채널 확장\n",
    "        expanded_channels = cnf.adjust_channels(cnf.input_channels, cnf.expand_ratio)\n",
    "        if expanded_channels != cnf.input_channels:\n",
    "            layers.append(\n",
    "                Conv2dNormActivation(cnf.input_channels, expanded_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=activation_layer)\n",
    "            )\n",
    "\n",
    "        # Depthwise Convolution: 깊이별 연산\n",
    "        layers.append(\n",
    "            Conv2dNormActivation(expanded_channels, expanded_channels, kernel_size=cnf.kernel, stride=cnf.stride, groups=expanded_channels, norm_layer=norm_layer, activation_layer=activation_layer)\n",
    "        )\n",
    "\n",
    "        # Squeeze and Excitation: 채널 중요도 조정\n",
    "        squeeze_channels = max(1, cnf.input_channels // 4) # 채널 축소 비율 설정\n",
    "        layers.append(se_layer(expanded_channels, squeeze_channels, activation=partial(nn.SiLU, inplace=True)))\n",
    "\n",
    "        # Project: 1x1 conv, 채널 축소\n",
    "        layers.append(\n",
    "            Conv2dNormActivation(expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None)\n",
    "        )\n",
    "\n",
    "        self.block = nn.Sequential(*layers) # 구성한 레이어들을 순차적으로 묶음\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\") # Stochastic Depth 적용\n",
    "        self.out_channels = cnf.out_channels # 출력 채널 수\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input) # 블록의 연산 수행\n",
    "        if self.use_res_connect: # 잔차 연결 적용 여부 확인\n",
    "            result = self.stochastic_depth(result) # Stochastic Depth 적용\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "# FusedMBConv (EfficientNetV2에서는 FusedMBConv를 사용)\n",
    "class FusedMBConv(nn.Module):\n",
    "    def __init__(self, cnf: _MBConvConfig, stochastic_depth_prob: float, norm_layer: Callable[..., nn.Module]) -> None:\n",
    "        super(FusedMBConv, self).__init__()\n",
    "        # stride 값이 1 또는 2가 아닌 경우 예외 발생\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError(\"illegal stride value\")\n",
    "        \n",
    "        # stride가 1이고 입력 채널과 출력 채널이 같으면 skip connection 사용\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.SiLU # 활성화 함수로 SiLU(Swish) 사용\n",
    "        # 확장된 채널 수 계산 (expand ratio를 곱한 값)\n",
    "        expanded_channels = cnf.adjust_channels(cnf.input_channels, cnf.expand_ratio)\n",
    "         # 입력 채널과 확장된 채널이 다를 경우 확장 단계 추가\n",
    "        if expanded_channels != cnf.input_channels:\n",
    "             # 확장 단계: 확장된 채널 수를 사용한 컨볼루션 레이어 추가\n",
    "            layers.append(\n",
    "                Conv2dNormActivation(cnf.input_channels, expanded_channels, kernel_size=cnf.kernel, stride=cnf.stride, norm_layer=norm_layer, activation_layer=activation_layer)\n",
    "            )\n",
    "\n",
    "            # Project: 1x1 Pointwise Conv로 채널 수를 출력 채널로 변경\n",
    "            layers.append(\n",
    "                Conv2dNormActivation(expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None)\n",
    "            )\n",
    "        else:\n",
    "            # 확장이 필요 없는 경우 단일 컨볼루션 레이어로 처리\n",
    "            layers.append(\n",
    "                Conv2dNormActivation(cnf.input_channels, cnf.out_channels, kernel_size=cnf.kernel, stride=cnf.stride, norm_layer=norm_layer, activation_layer=activation_layer)\n",
    "            )\n",
    "        # 생성된 레이어 리스트를 nn.Sequential로 묶어 블록 생성\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "         # Stochastic Depth 적용\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "        \n",
    "        # 출력 채널 저장\n",
    "        self.out_channels = cnf.out_channels\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            # Stochastic Depth로 일부 입력 무작위 드롭\n",
    "            result = self.stochastic_depth(result)\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "# 주어진 값(value)을 특정 값(divisor)로 나누어 떨어지도록 조정하는 함수\n",
    "def _make_divisible(value: int, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    if min_value is None:\n",
    "        min_value = divisor # 최소값이 지정되지 않았으면 divisor 사용\n",
    "    new_value = max(min_value, int(value + divisor / 2) // divisor * divisor)\n",
    "     # 조정된 값이 원래 값의 90% 미만이면 divisor를 더해 조정\n",
    "    if new_value < 0.9 * value:\n",
    "        new_value += divisor\n",
    "    return new_value\n",
    "\n",
    "\n",
    "# FusedMBConvConfig 객체로 inverted_residual_setting을 구성\n",
    "inverted_residual_setting = [\n",
    "    FusedMBConvConfig(1, 3, 2, 32, 16, 2),\n",
    "    FusedMBConvConfig(2, 3, 2, 16, 32, 4),\n",
    "    FusedMBConvConfig(3, 3, 2, 32, 64, 4),\n",
    "    FusedMBConvConfig(4, 3, 1, 64, 128, 6),\n",
    "    FusedMBConvConfig(5, 3, 2, 128, 256, 15),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, Sequence, Union, Tuple\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "# WeightsEnum에 필요한 경우 사용할 수 있는 자리 표시자 클래스\n",
    "class WeightsEnum:\n",
    "    pass\n",
    "\n",
    "# 학습된 가중치를 저장하는 Weights 클래스 정의\n",
    "class Weights:\n",
    "    def __init__(self, url: str, transforms: Callable, meta: dict):\n",
    "        self.url = url\n",
    "        self.transforms = transforms\n",
    "        self.meta = meta\n",
    "\n",
    "# 이미지 분류를 위한 데이터 변환 클래스\n",
    "class ImageClassification:\n",
    "    def __init__(self, crop_size: int, resize_size: int, interpolation: str):\n",
    "        self.crop_size = crop_size  # 자를 이미지 크기\n",
    "        self.resize_size = resize_size # 리사이즈할 이미지 크기\n",
    "        self.interpolation = interpolation # 이미지 보간(interpolation) 방식\n",
    "\n",
    "# EfficientNet V2 모델의 가중치 Enum 정의\n",
    "class EfficientNet_V2_S_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\",\n",
    "        transforms=partial(\n",
    "            ImageClassification,\n",
    "            crop_size=384,\n",
    "            resize_size=384,\n",
    "            interpolation=\"BILINEAR\",  # You can also import InterpolationMode.BILINEAR if you prefer\n",
    "        ),\n",
    "        meta={\n",
    "            \"num_params\": 21458488,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 84.228,\n",
    "                    \"acc@5\": 96.878,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 8.366,\n",
    "            \"_file_size\": 82.704,\n",
    "            \"_docs\": \"\"\"\n",
    "                These weights improve upon the results of the original paper by using a modified version of TorchVision's\n",
    "                `new training recipe\n",
    "                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.\n",
    "            \"\"\",\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1  # 기본 가중치 설정\n",
    "\n",
    "# EfficientNet V2 모델 클래스 정의\n",
    "class EfficientNetV2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]],\n",
    "        dropout: float,\n",
    "        stochastic_depth_prob: float = 0.2, # 확률적으로 레이어를 드롭\n",
    "        num_classes: int = 1000, # 출력 클래스 수\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        last_channel: Optional[int] = None, # 마지막 출력 채널 수\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # 입력 검증\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty\")\n",
    "        elif not isinstance(inverted_residual_setting, Sequence) or not all([isinstance(s, _MBConvConfig) for s in inverted_residual_setting]):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[MBConvConfig]\")\n",
    "        \n",
    "        # 기본 정규화 레이어를 BatchNorm2d로 설정\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        layers: List[nn.Module] = [] # 모델 레이어를 저장할 리스트\n",
    "        \n",
    "        # 초기 Conv 레이어 추가\n",
    "        firstconv_output_channels = inverted_residual_setting[0].input_channels\n",
    "        layers.append(\n",
    "            Conv2dNormActivation(\n",
    "                3, firstconv_output_channels, kernel_size=3, stride=2, norm_layer=norm_layer, activation_layer=nn.SiLU\n",
    "            )\n",
    "        )\n",
    "        # MBConv 블록 추가\n",
    "        total_stage_blocks = sum(cnf.num_layers for cnf in inverted_residual_setting)\n",
    "        stage_block_id = 0\n",
    "        for cnf in inverted_residual_setting:\n",
    "            stage: List[nn.Module] = []\n",
    "            for _ in range(cnf.num_layers):\n",
    "                block_cnf = copy.copy(cnf)\n",
    "                if stage:\n",
    "                    block_cnf.input_channels = block_cnf.out_channels\n",
    "                    block_cnf.stride = 1\n",
    "                sd_prob = stochastic_depth_prob * float(stage_block_id) / total_stage_blocks\n",
    "                stage.append(block_cnf.block(block_cnf, sd_prob, norm_layer))\n",
    "                stage_block_id += 1\n",
    "            layers.append(nn.Sequential(*stage))\n",
    "        # 마지막 Conv 레이어 추가\n",
    "        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
    "        lastconv_output_channels = last_channel if last_channel is not None else 4 * lastconv_input_channels\n",
    "        layers.append(\n",
    "            Conv2dNormActivation(\n",
    "                lastconv_input_channels,\n",
    "                lastconv_output_channels,\n",
    "                kernel_size=1,\n",
    "                norm_layer=norm_layer,\n",
    "                activation_layer=nn.SiLU,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 특징 추출 파트 설정\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1) # Adaptive Average Pooling\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout, inplace=True),\n",
    "            nn.Linear(lastconv_output_channels, 5),  # num_classes를 5로 설정\n",
    "            )\n",
    "\n",
    "        # 가중치 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init_range = 1.0 / math.sqrt(m.out_features)\n",
    "                nn.init.uniform_(m.weight, -init_range, init_range)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    # 모델 순전파 구현 (내부용)\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    # forward 함수\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "# EfficientNet 생성 함수\n",
    "def _efficientnet(\n",
    "    inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]],\n",
    "    dropout: float,\n",
    "    last_channel: Optional[int],\n",
    "    weights: Optional[WeightsEnum], # 사전 학습된 가중치\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> EfficientNetV2:\n",
    "    if weights is not None:\n",
    "        _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "\n",
    "    model = EfficientNetV2(inverted_residual_setting, dropout, last_channel=last_channel, **kwargs)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress, check_hash=True))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Early stopping 포함 8 epoch까지 학습한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5457, Accuracy: 0.2956, F1 Score: 0.3008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7002, Accuracy: 0.4338, F1 Score: 0.2181\n",
      "Epoch [1/20], Loss: 0.7002, Accuracy: 0.4338, F1 Score: 0.2181\n",
      "Validation score improved (0.218105 --> 0.218105). Saving model...\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4280, Accuracy: 0.3928, F1 Score: 0.4567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4044, Accuracy: 0.4464, F1 Score: 0.4235\n",
      "Epoch [2/20], Loss: 0.4044, Accuracy: 0.4464, F1 Score: 0.4235\n",
      "Validation score improved (0.423494 --> 0.423494). Saving model...\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3886, Accuracy: 0.4503, F1 Score: 0.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3894, Accuracy: 0.4776, F1 Score: 0.5160\n",
      "Epoch [3/20], Loss: 0.3894, Accuracy: 0.4776, F1 Score: 0.5160\n",
      "Validation score improved (0.516011 --> 0.516011). Saving model...\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3680, Accuracy: 0.4851, F1 Score: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3988, Accuracy: 0.4921, F1 Score: 0.4535\n",
      "Epoch [4/20], Loss: 0.3988, Accuracy: 0.4921, F1 Score: 0.4535\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3546, Accuracy: 0.5040, F1 Score: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3435, Accuracy: 0.5387, F1 Score: 0.5897\n",
      "Epoch [5/20], Loss: 0.3435, Accuracy: 0.5387, F1 Score: 0.5897\n",
      "Validation score improved (0.589688 --> 0.589688). Saving model...\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3454, Accuracy: 0.5229, F1 Score: 0.6327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4322, Accuracy: 0.3458, F1 Score: 0.5104\n",
      "Epoch [6/20], Loss: 0.4322, Accuracy: 0.3458, F1 Score: 0.5104\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3317, Accuracy: 0.5387, F1 Score: 0.6516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3485, Accuracy: 0.5242, F1 Score: 0.5440\n",
      "Epoch [7/20], Loss: 0.3485, Accuracy: 0.5242, F1 Score: 0.5440\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3257, Accuracy: 0.5483, F1 Score: 0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3435, Accuracy: 0.4921, F1 Score: 0.5892\n",
      "Epoch [8/20], Loss: 0.3435, Accuracy: 0.4921, F1 Score: 0.5892\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping triggered after 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3545, Accuracy: 0.4884, F1 Score: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from functools import partial\n",
    "\n",
    "# EfficientNetV2-S 모델 설정 및 가중치 불러오기\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "\n",
    "def _efficientnet_conf(\n",
    "    arch: str,\n",
    "    **kwargs: Any,\n",
    ") -> Tuple[Sequence[Union[MBConvConfig, FusedMBConvConfig]], Optional[int]]:\n",
    "    inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]]\n",
    "    \n",
    "    # 'efficientnet_v2_s' 아키텍처만 사용\n",
    "    if arch == \"efficientnet_v2_s\":\n",
    "        inverted_residual_setting = [\n",
    "            FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
    "            FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
    "            FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
    "            MBConvConfig(4, 3, 2, 64, 128, 6),\n",
    "            MBConvConfig(6, 3, 1, 128, 160, 9),\n",
    "            MBConvConfig(6, 3, 2, 160, 256, 15),\n",
    "        ]\n",
    "        last_channel = 1280\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
    "\n",
    "    return inverted_residual_setting, last_channel\n",
    "\n",
    "\n",
    "def efficientnet_v2_s(\n",
    "    *, weights: Optional[EfficientNet_V2_S_Weights] = None, progress: bool = True, **kwargs: Any\n",
    ") -> EfficientNetV2:\n",
    "    \"\"\"\n",
    "    Constructs an EfficientNetV2-S architecture and loads pre-trained weights.\n",
    "    \"\"\"\n",
    "    weights = EfficientNet_V2_S_Weights.verify(weights)\n",
    "\n",
    "    inverted_residual_setting, last_channel = _efficientnet_conf(\"efficientnet_v2_s\")\n",
    "    model = _efficientnet(\n",
    "        inverted_residual_setting,\n",
    "        kwargs.pop(\"dropout\", 0.2),\n",
    "        last_channel,\n",
    "        weights,\n",
    "        progress,\n",
    "        norm_layer=partial(nn.BatchNorm2d, eps=1e-03),\n",
    "        **kwargs,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 모델 불러오기\n",
    "# EfficientNetV2 모델에 설정을 전달\n",
    "model = EfficientNetV2(\n",
    "    inverted_residual_setting=inverted_residual_setting,\n",
    "    dropout=0.2,\n",
    "    num_classes=5\n",
    ")\n",
    "\n",
    "# Loss Function, Optimizer 설정\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# EarlyStopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.epochs_no_improve = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_wts = None\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.epochs_no_improve += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.epochs_no_improve} out of {self.patience}')\n",
    "            if self.epochs_no_improve >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "            self.epochs_no_improve = 0\n",
    "\n",
    "        return self.early_stop\n",
    "\n",
    "    def save_checkpoint(self, score, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation score improved ({self.best_score:.6f} --> {score:.6f}). Saving model...')\n",
    "        self.best_model_wts = model.state_dict()\n",
    "\n",
    "# 모델 학습과 평가 함수 정의\n",
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False, ncols=100):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False, ncols=100):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predictions.extend(torch.sigmoid(outputs).cpu().numpy() > 0.5)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "# 모델 학습 실행\n",
    "num_epochs = 20\n",
    "patience = 3  # 조기 중지 시 허용되는 에폭 수\n",
    "best_loss = float('inf')  # 초기값을 무한대로 설정\n",
    "\n",
    "# EarlyStopping 객체 초기화\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc, train_f1 = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_acc, val_f1 = evaluate_model(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # EarlyStopping 체크\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}')\n",
    "    \n",
    "    # 모델 성능 개선 여부 확인\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # Early stopping 기준: F1 Score를 기준으로 EarlyStopping 체크\n",
    "    if early_stopping(val_f1, model):\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "# 최상의 모델 불러오기\n",
    "model.load_state_dict(early_stopping.best_model_wts)\n",
    "\n",
    "# Test 모델 평가\n",
    "test_loss, test_accuracy, test_f1 = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Early stopping 없이 10 epoch 학습한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5584, Accuracy: 0.2779, F1 Score: 0.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5302, Accuracy: 0.1650, F1 Score: 0.3306\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4298, Accuracy: 0.3857, F1 Score: 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3934, Accuracy: 0.4832, F1 Score: 0.4950\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3936, Accuracy: 0.4419, F1 Score: 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3790, Accuracy: 0.4856, F1 Score: 0.5158\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3709, Accuracy: 0.4759, F1 Score: 0.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4008, Accuracy: 0.4529, F1 Score: 0.5441\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3542, Accuracy: 0.5052, F1 Score: 0.6188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3403, Accuracy: 0.5247, F1 Score: 0.5589\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3387, Accuracy: 0.5264, F1 Score: 0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3368, Accuracy: 0.5270, F1 Score: 0.5799\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3307, Accuracy: 0.5451, F1 Score: 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3431, Accuracy: 0.5564, F1 Score: 0.6320\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3221, Accuracy: 0.5576, F1 Score: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3835, Accuracy: 0.5336, F1 Score: 0.5649\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3138, Accuracy: 0.5662, F1 Score: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3319, Accuracy: 0.5256, F1 Score: 0.6951\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3091, Accuracy: 0.5745, F1 Score: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3285, Accuracy: 0.5788, F1 Score: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3428, Accuracy: 0.5765, F1 Score: 0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from functools import partial\n",
    "\n",
    "# EfficientNetV2-S 모델 설정 및 가중치 불러오기\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "\n",
    "def _efficientnet_conf(\n",
    "    arch: str,\n",
    "    **kwargs: Any,\n",
    ") -> Tuple[Sequence[Union[MBConvConfig, FusedMBConvConfig]], Optional[int]]:\n",
    "    inverted_residual_setting: Sequence[Union[MBConvConfig, FusedMBConvConfig]]\n",
    "    \n",
    "    # 'efficientnet_v2_s' 아키텍처만 사용\n",
    "    if arch == \"efficientnet_v2_s\":\n",
    "        inverted_residual_setting = [\n",
    "            FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
    "            FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
    "            FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
    "            MBConvConfig(4, 3, 2, 64, 128, 6),\n",
    "            MBConvConfig(6, 3, 1, 128, 160, 9),\n",
    "            MBConvConfig(6, 3, 2, 160, 256, 15),\n",
    "        ]\n",
    "        last_channel = 1280\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
    "\n",
    "    return inverted_residual_setting, last_channel\n",
    "\n",
    "\n",
    "def efficientnet_v2_s(\n",
    "    *, weights: Optional[EfficientNet_V2_S_Weights] = None, progress: bool = True, **kwargs: Any\n",
    ") -> EfficientNetV2:\n",
    "    \"\"\"\n",
    "    Constructs an EfficientNetV2-S architecture and loads pre-trained weights.\n",
    "    \"\"\"\n",
    "    weights = EfficientNet_V2_S_Weights.verify(weights)\n",
    "\n",
    "    inverted_residual_setting, last_channel = _efficientnet_conf(\"efficientnet_v2_s\")\n",
    "    model = _efficientnet(\n",
    "        inverted_residual_setting,\n",
    "        kwargs.pop(\"dropout\", 0.2),\n",
    "        last_channel,\n",
    "        weights,\n",
    "        progress,\n",
    "        norm_layer=partial(nn.BatchNorm2d, eps=1e-03),\n",
    "        **kwargs,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 모델 불러오기\n",
    "# EfficientNetV2 모델에 설정을 전달\n",
    "model = EfficientNetV2(\n",
    "    inverted_residual_setting=inverted_residual_setting,\n",
    "    dropout=0.2,\n",
    "    num_classes=5\n",
    ")\n",
    "\n",
    "# Loss Function, Optimizer 설정\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 모델 학습과 평가 함수 정의\n",
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False, ncols=100):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False, ncols=100):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predictions.extend(torch.sigmoid(outputs).cpu().numpy() > 0.5)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "# 모델 학습 실행\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')  # 초기값을 무한대로 설정\n",
    "best_model_weights = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # Train\n",
    "    train_epoch_loss, train_epoch_acc, train_epoch_f1 = train_model(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    print(\n",
    "        f\"Train Loss: {train_epoch_loss:.4f}, \"\n",
    "        f\"Accuracy: {train_epoch_acc:.4f}, \"\n",
    "        f\"F1 Score: {train_epoch_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Validation\n",
    "    val_epoch_loss, val_epoch_acc, val_epoch_f1 = evaluate_model(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation Loss: {val_epoch_loss:.4f}, \"\n",
    "        f\"Accuracy: {val_epoch_acc:.4f}, \"\n",
    "        f\"F1 Score: {val_epoch_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 최적 성능 모델의 가중치 저장\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_model_weights = model.state_dict()\n",
    "\n",
    "# 최상의 모델 불러오기\n",
    "model.load_state_dict(best_model_weights)\n",
    "\n",
    "# Test 모델 평가\n",
    "test_loss, test_acc, test_f1 = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
