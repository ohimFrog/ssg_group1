{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wpPnwC1VIvH"
   },
   "source": [
    "# **[심층신경망개론] Group 1 DeiT 구현**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OqCwzxU9Aht",
    "outputId": "77744cd4-f5d2-40f4-d228-124479085824"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_177267/3708884475.py:59: UserWarning: Overwriting deit_tiny_patch16_224 in registry with __main__.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:76: UserWarning: Overwriting deit_small_patch16_224 in registry with __main__.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:91: UserWarning: Overwriting deit_base_patch16_224 in registry with __main__.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:106: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with __main__.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:121: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with __main__.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:136: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with __main__.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:151: UserWarning: Overwriting deit_base_patch16_384 in registry with __main__.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/tmp/ipykernel_177267/3708884475.py:166: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with __main__.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "__all__ = [\n",
    "    'deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224',\n",
    "    'deit_tiny_distilled_patch16_224', 'deit_small_distilled_patch16_224',\n",
    "    'deit_base_distilled_patch16_224', 'deit_base_patch16_384',\n",
    "    'deit_base_distilled_patch16_384',\n",
    "]\n",
    "\n",
    "\n",
    "class DistilledVisionTransformer(VisionTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.embed_dim))\n",
    "        self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if self.num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.dist_token, std=.02)\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.head_dist.apply(self._init_weights)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
    "        # with slight modifications to add the dist_token\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        dist_token = self.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0], x[:, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x_dist = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        x_dist = self.head_dist(x_dist)\n",
    "        if self.training:\n",
    "            return x, x_dist\n",
    "        else:\n",
    "            # during inference, return the average of both classifier predictions\n",
    "            return (x + x_dist) / 2\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=16, embed_dim=192, depth=12, num_heads=3, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes=num_classes,\n",
    "        drop_rate=drop_rate, drop_path_rate=drop_path_rate, ** 0.5, **kwargs\n",
    "    )\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_small_patch16_224(pretrained=False, **kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=16, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes = num_classes, drop_rate=drop_rate, drop_path_rate=drop_path_rate,  **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_base_patch16_224(pretrained=False, **kwargs):\n",
    "    model = VisionTransformer(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes = num_classes, drop_rate=drop_rate, drop_path_rate=drop_path_rate, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_tiny_distilled_patch16_224(pretrained=False, num_classes = 5, drop_rate= 0.2, drop_path_rate=0.1, **kwargs):\n",
    "    model = DistilledVisionTransformer(\n",
    "        patch_size=16, embed_dim=192, depth=12, num_heads=3, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes = num_classes, drop_rate=drop_rate, drop_path_rate=drop_path_rate, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_small_distilled_patch16_224(pretrained=False, num_classes = 5, drop_rate= 0.2, drop_path_rate=0.1, **kwargs):\n",
    "    model = DistilledVisionTransformer(\n",
    "        patch_size=16, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes = num_classes, drop_rate=drop_rate, drop_path_rate=drop_path_rate, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_base_distilled_patch16_224(pretrained=False, num_classes = 5, drop_rate= 0.2, drop_path_rate=0.1, **kwargs):\n",
    "    model = DistilledVisionTransformer(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes = num_classes, drop_rate=drop_rate, drop_path_rate=drop_path_rate, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_base_patch16_384(pretrained=False, **kwargs):\n",
    "    model = VisionTransformer(\n",
    "        img_size=384, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
    "    model = DistilledVisionTransformer(\n",
    "        img_size=384, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    if pretrained:\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KplhsmeAUFxt",
    "outputId": "9ef2c90a-5dac-4928-8f00-039bfa30bb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wfdb in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (4.1.2)\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (0.12.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.10.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.8.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from wfdb) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gaya/.local/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gaya/.local/lib/python3.11/site-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from requests>=2.8.1->wfdb) (2024.8.30)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from SoundFile>=0.10.0->wfdb) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaya/anaconda3/envs/group4/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaGYao_jRQf9",
    "outputId": "f316a647-8390-4a87-9c43-e1a2c93a228a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (17084, 1000, 12), Labels: (17084, 5)\n",
      "Validation Data Shape: (2146, 1000, 12), Labels: (2146, 5)\n",
      "Test Data Shape: (2158, 1000, 12), Labels: (2158, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    \"\"\"df.index를 기준으로 데이터를 로드\"\"\"\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_lr']]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_hr']]\n",
    "    # df.index에 있는 데이터만 로드\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "# 데이터 경로 설정\n",
    "path = \"./\"\n",
    "sampling_rate = 100\n",
    "\n",
    "# PTB-XL 데이터베이스 로드\n",
    "df = pd.read_csv(os.path.join(path, 'ptbxl_database.csv'), index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# 진단 정보 로드\n",
    "agg_df = pd.read_csv(os.path.join(path, 'scp_statements.csv'), index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    \"\"\"진단 클래스를 매핑하는 함수\"\"\"\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# 진단 클래스 매핑\n",
    "df['diagnostic_superclass'] = df.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# 빈 클래스 제거\n",
    "df = df[df['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Raw data 로드\n",
    "X = load_raw_data(df, sampling_rate, path)\n",
    "\n",
    "# 크기 확인\n",
    "assert len(X) == len(df), \"X와 df의 크기가 일치하지 않습니다.\"\n",
    "\n",
    "# 데이터셋 분리\n",
    "test_fold = 10\n",
    "val_fold = 9\n",
    "\n",
    "train_filter = (df.strat_fold != test_fold) & (df.strat_fold != val_fold)\n",
    "val_filter = df.strat_fold == val_fold\n",
    "test_filter = df.strat_fold == test_fold\n",
    "\n",
    "X_train = X[train_filter]\n",
    "y_train = list(df[train_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_val = X[val_filter]\n",
    "y_val = list(df[val_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_test = X[test_filter]\n",
    "y_test = list(df[test_filter]['diagnostic_superclass'])\n",
    "\n",
    "# 다중 라벨 이진화\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Labels: {y_train_bin.shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}, Labels: {y_val_bin.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}, Labels: {y_test_bin.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h649OTLEVVqN",
    "outputId": "3f6ea68d-6e5f-4178-b0cd-0fa129b3ba13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Dataset for ECG Data\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            # ECG 데이터를 3채널로 확장\n",
    "            sample = self.transform(sample)\n",
    "        return sample.float(), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Numpy 배열 -> Tensor\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),  # 1채널 데이터를 3채널로 확장\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = ECGDataset(X_train, y_train_bin, transform=transform)\n",
    "val_dataset = ECGDataset(X_val, y_val_bin, transform=transform)\n",
    "test_dataset = ECGDataset(X_test, y_test_bin, transform=transform)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 확인\n",
    "class_names = mlb.classes_\n",
    "print(f\"Classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GmzvYTDjEER7"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=None,\n",
    "    num_epochs=100,\n",
    "    patience=3,\n",
    "    learning_rate=0.001,\n",
    "    checkpoint_path='deit_checkpoint.pth'\n",
    "):\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 학습 상태 초기화\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    logs = {'train_loss': [], 'train_accuracy': [], 'train_f1': []}\n",
    "\n",
    "    if val_loader:\n",
    "        logs['val_loss'] = []\n",
    "        logs['val_accuracy'] = []\n",
    "        logs['val_f1'] = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        # Training loop\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)  # 모델 forward\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "        # Train metrics\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "        f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "        logs['train_loss'].append(epoch_loss)\n",
    "        logs['train_accuracy'].append(accuracy)\n",
    "        logs['train_f1'].append(f1)\n",
    "\n",
    "        # Validation loop (if provided)\n",
    "        if val_loader:\n",
    "            val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, criterion)\n",
    "            logs['val_loss'].append(val_loss)\n",
    "            logs['val_accuracy'].append(val_accuracy)\n",
    "            logs['val_f1'].append(val_f1)\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "        # Checkpoint and early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Best model 로드\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"Best model loaded.\")\n",
    "    return logs\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    \"\"\"모델 검증 및 평가.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = accuracy_score(np.vstack(all_labels), np.vstack(all_preds))\n",
    "    f1 = f1_score(np.vstack(all_labels), np.vstack(all_preds), average='macro')\n",
    "\n",
    "    return epoch_loss, accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNPuE3FjF_PE",
    "outputId": "e4217f50-fffc-45cd-ece8-a22b1baf31a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100...\n",
      "Epoch 1, Train Loss: 0.5578, Accuracy: 0.1330, F1 Score: 0.1335\n",
      "Epoch 1, Val Loss: 0.4708, Val Accuracy: 0.3756, Val F1: 0.2422\n",
      "Checkpoint saved at epoch 1.\n",
      "Starting epoch 2/100...\n",
      "Epoch 2, Train Loss: 0.4959, Accuracy: 0.3119, F1 Score: 0.3354\n",
      "Epoch 2, Val Loss: 0.4345, Val Accuracy: 0.4334, Val F1: 0.3853\n",
      "Checkpoint saved at epoch 2.\n",
      "Starting epoch 3/100...\n",
      "Epoch 3, Train Loss: 0.4703, Accuracy: 0.3433, F1 Score: 0.4287\n",
      "Epoch 3, Val Loss: 0.4108, Val Accuracy: 0.4362, Val F1: 0.5540\n",
      "Checkpoint saved at epoch 3.\n",
      "Starting epoch 4/100...\n",
      "Epoch 4, Train Loss: 0.4573, Accuracy: 0.3620, F1 Score: 0.4658\n",
      "Epoch 4, Val Loss: 0.4054, Val Accuracy: 0.4366, Val F1: 0.4980\n",
      "Checkpoint saved at epoch 4.\n",
      "Starting epoch 5/100...\n",
      "Epoch 5, Train Loss: 0.4488, Accuracy: 0.3745, F1 Score: 0.4869\n",
      "Epoch 5, Val Loss: 0.3955, Val Accuracy: 0.4627, Val F1: 0.5414\n",
      "Checkpoint saved at epoch 5.\n",
      "Starting epoch 6/100...\n",
      "Epoch 6, Train Loss: 0.4406, Accuracy: 0.3845, F1 Score: 0.4989\n",
      "Epoch 6, Val Loss: 0.3871, Val Accuracy: 0.5065, Val F1: 0.5551\n",
      "Checkpoint saved at epoch 6.\n",
      "Starting epoch 7/100...\n",
      "Epoch 7, Train Loss: 0.4339, Accuracy: 0.3904, F1 Score: 0.5091\n",
      "Epoch 7, Val Loss: 0.3819, Val Accuracy: 0.4884, Val F1: 0.5592\n",
      "Checkpoint saved at epoch 7.\n",
      "Starting epoch 8/100...\n",
      "Epoch 8, Train Loss: 0.4287, Accuracy: 0.3962, F1 Score: 0.5228\n",
      "Epoch 8, Val Loss: 0.3774, Val Accuracy: 0.5005, Val F1: 0.5461\n",
      "Checkpoint saved at epoch 8.\n",
      "Starting epoch 9/100...\n",
      "Epoch 9, Train Loss: 0.4238, Accuracy: 0.4039, F1 Score: 0.5368\n",
      "Epoch 9, Val Loss: 0.3763, Val Accuracy: 0.4888, Val F1: 0.5758\n",
      "Checkpoint saved at epoch 9.\n",
      "Starting epoch 10/100...\n",
      "Epoch 10, Train Loss: 0.4196, Accuracy: 0.4151, F1 Score: 0.5444\n",
      "Epoch 10, Val Loss: 0.3643, Val Accuracy: 0.5172, Val F1: 0.6048\n",
      "Checkpoint saved at epoch 10.\n",
      "Starting epoch 11/100...\n",
      "Epoch 11, Train Loss: 0.4137, Accuracy: 0.4187, F1 Score: 0.5509\n",
      "Epoch 11, Val Loss: 0.3695, Val Accuracy: 0.5112, Val F1: 0.5694\n",
      "Checkpoint saved at epoch 11.\n",
      "Starting epoch 12/100...\n",
      "Epoch 12, Train Loss: 0.4099, Accuracy: 0.4220, F1 Score: 0.5597\n",
      "Epoch 12, Val Loss: 0.3669, Val Accuracy: 0.4916, Val F1: 0.6189\n",
      "Checkpoint saved at epoch 12.\n",
      "Starting epoch 13/100...\n",
      "Epoch 13, Train Loss: 0.4039, Accuracy: 0.4301, F1 Score: 0.5676\n",
      "Epoch 13, Val Loss: 0.3655, Val Accuracy: 0.5126, Val F1: 0.5790\n",
      "Checkpoint saved at epoch 13.\n",
      "Starting epoch 14/100...\n",
      "Epoch 14, Train Loss: 0.4020, Accuracy: 0.4330, F1 Score: 0.5727\n",
      "Epoch 14, Val Loss: 0.3589, Val Accuracy: 0.5093, Val F1: 0.5974\n",
      "Checkpoint saved at epoch 14.\n",
      "Starting epoch 15/100...\n",
      "Epoch 15, Train Loss: 0.3976, Accuracy: 0.4404, F1 Score: 0.5785\n",
      "Epoch 15, Val Loss: 0.3551, Val Accuracy: 0.5377, Val F1: 0.6114\n",
      "Checkpoint saved at epoch 15.\n",
      "Starting epoch 16/100...\n",
      "Epoch 16, Train Loss: 0.3902, Accuracy: 0.4430, F1 Score: 0.5793\n",
      "Epoch 16, Val Loss: 0.3616, Val Accuracy: 0.4930, Val F1: 0.5861\n",
      "Checkpoint saved at epoch 16.\n",
      "Starting epoch 17/100...\n",
      "Epoch 17, Train Loss: 0.3895, Accuracy: 0.4484, F1 Score: 0.5888\n",
      "Epoch 17, Val Loss: 0.3601, Val Accuracy: 0.5214, Val F1: 0.6207\n",
      "Checkpoint saved at epoch 17.\n",
      "Starting epoch 18/100...\n",
      "Epoch 18, Train Loss: 0.3839, Accuracy: 0.4517, F1 Score: 0.5961\n",
      "Epoch 18, Val Loss: 0.3564, Val Accuracy: 0.5349, Val F1: 0.6273\n",
      "Checkpoint saved at epoch 18.\n",
      "Starting epoch 19/100...\n",
      "Epoch 19, Train Loss: 0.3789, Accuracy: 0.4661, F1 Score: 0.6070\n",
      "Epoch 19, Val Loss: 0.3663, Val Accuracy: 0.5075, Val F1: 0.6028\n",
      "Checkpoint saved at epoch 19.\n",
      "Starting epoch 20/100...\n",
      "Epoch 20, Train Loss: 0.3764, Accuracy: 0.4620, F1 Score: 0.6090\n",
      "Epoch 20, Val Loss: 0.3587, Val Accuracy: 0.5266, Val F1: 0.6352\n",
      "Checkpoint saved at epoch 20.\n",
      "Starting epoch 21/100...\n",
      "Epoch 21, Train Loss: 0.3717, Accuracy: 0.4749, F1 Score: 0.6221\n",
      "Epoch 21, Val Loss: 0.3642, Val Accuracy: 0.5214, Val F1: 0.6104\n",
      "Checkpoint saved at epoch 21.\n",
      "Starting epoch 22/100...\n",
      "Epoch 22, Train Loss: 0.3681, Accuracy: 0.4748, F1 Score: 0.6218\n",
      "Epoch 22, Val Loss: 0.3656, Val Accuracy: 0.5536, Val F1: 0.6073\n",
      "Checkpoint saved at epoch 22.\n",
      "Starting epoch 23/100...\n",
      "Epoch 23, Train Loss: 0.3625, Accuracy: 0.4811, F1 Score: 0.6289\n",
      "Epoch 23, Val Loss: 0.3566, Val Accuracy: 0.5391, Val F1: 0.6163\n",
      "Checkpoint saved at epoch 23.\n",
      "Starting epoch 24/100...\n",
      "Epoch 24, Train Loss: 0.3587, Accuracy: 0.4886, F1 Score: 0.6357\n",
      "Epoch 24, Val Loss: 0.3645, Val Accuracy: 0.5345, Val F1: 0.6205\n",
      "Checkpoint saved at epoch 24.\n",
      "Starting epoch 25/100...\n",
      "Epoch 25, Train Loss: 0.3524, Accuracy: 0.4960, F1 Score: 0.6438\n",
      "Epoch 25, Val Loss: 0.3573, Val Accuracy: 0.5228, Val F1: 0.6008\n",
      "Checkpoint saved at epoch 25.\n",
      "Starting epoch 26/100...\n",
      "Epoch 26, Train Loss: 0.3479, Accuracy: 0.5030, F1 Score: 0.6538\n",
      "Epoch 26, Val Loss: 0.3666, Val Accuracy: 0.5391, Val F1: 0.6192\n",
      "Checkpoint saved at epoch 26.\n",
      "Starting epoch 27/100...\n",
      "Epoch 27, Train Loss: 0.3419, Accuracy: 0.5057, F1 Score: 0.6558\n",
      "Epoch 27, Val Loss: 0.3639, Val Accuracy: 0.5219, Val F1: 0.6286\n",
      "Checkpoint saved at epoch 27.\n",
      "Starting epoch 28/100...\n",
      "Epoch 28, Train Loss: 0.3378, Accuracy: 0.5143, F1 Score: 0.6658\n",
      "Epoch 28, Val Loss: 0.3666, Val Accuracy: 0.5158, Val F1: 0.6346\n",
      "Checkpoint saved at epoch 28.\n",
      "Starting epoch 29/100...\n",
      "Epoch 29, Train Loss: 0.3310, Accuracy: 0.5204, F1 Score: 0.6761\n",
      "Epoch 29, Val Loss: 0.3715, Val Accuracy: 0.5377, Val F1: 0.6093\n",
      "Checkpoint saved at epoch 29.\n",
      "Starting epoch 30/100...\n",
      "Epoch 30, Train Loss: 0.3261, Accuracy: 0.5249, F1 Score: 0.6779\n",
      "Epoch 30, Val Loss: 0.3779, Val Accuracy: 0.5438, Val F1: 0.6233\n",
      "Checkpoint saved at epoch 30.\n",
      "Starting epoch 31/100...\n",
      "Epoch 31, Train Loss: 0.3229, Accuracy: 0.5300, F1 Score: 0.6845\n",
      "Epoch 31, Val Loss: 0.3769, Val Accuracy: 0.5363, Val F1: 0.6175\n",
      "Checkpoint saved at epoch 31.\n",
      "Starting epoch 32/100...\n",
      "Epoch 32, Train Loss: 0.3128, Accuracy: 0.5433, F1 Score: 0.6955\n",
      "Epoch 32, Val Loss: 0.3846, Val Accuracy: 0.5200, Val F1: 0.6257\n",
      "Checkpoint saved at epoch 32.\n",
      "Starting epoch 33/100...\n",
      "Epoch 33, Train Loss: 0.3086, Accuracy: 0.5451, F1 Score: 0.7001\n",
      "Epoch 33, Val Loss: 0.3884, Val Accuracy: 0.5382, Val F1: 0.6167\n",
      "Checkpoint saved at epoch 33.\n",
      "Starting epoch 34/100...\n",
      "Epoch 34, Train Loss: 0.3032, Accuracy: 0.5515, F1 Score: 0.7051\n",
      "Epoch 34, Val Loss: 0.3955, Val Accuracy: 0.5154, Val F1: 0.6042\n",
      "Checkpoint saved at epoch 34.\n",
      "Starting epoch 35/100...\n",
      "Epoch 35, Train Loss: 0.2949, Accuracy: 0.5627, F1 Score: 0.7215\n",
      "Epoch 35, Val Loss: 0.4111, Val Accuracy: 0.5093, Val F1: 0.6240\n",
      "Checkpoint saved at epoch 35.\n",
      "Starting epoch 36/100...\n",
      "Epoch 36, Train Loss: 0.2906, Accuracy: 0.5678, F1 Score: 0.7267\n",
      "Epoch 36, Val Loss: 0.4056, Val Accuracy: 0.5326, Val F1: 0.6243\n",
      "Checkpoint saved at epoch 36.\n",
      "Starting epoch 37/100...\n",
      "Epoch 37, Train Loss: 0.2850, Accuracy: 0.5759, F1 Score: 0.7313\n",
      "Epoch 37, Val Loss: 0.4110, Val Accuracy: 0.5135, Val F1: 0.6044\n",
      "Checkpoint saved at epoch 37.\n",
      "Starting epoch 38/100...\n",
      "Epoch 38, Train Loss: 0.2762, Accuracy: 0.5818, F1 Score: 0.7383\n",
      "Epoch 38, Val Loss: 0.4265, Val Accuracy: 0.5280, Val F1: 0.6131\n",
      "Checkpoint saved at epoch 38.\n",
      "Starting epoch 39/100...\n",
      "Epoch 39, Train Loss: 0.2719, Accuracy: 0.5883, F1 Score: 0.7461\n",
      "Epoch 39, Val Loss: 0.4320, Val Accuracy: 0.5214, Val F1: 0.6233\n",
      "Checkpoint saved at epoch 39.\n",
      "Starting epoch 40/100...\n",
      "Epoch 40, Train Loss: 0.2706, Accuracy: 0.5928, F1 Score: 0.7495\n",
      "Epoch 40, Val Loss: 0.4416, Val Accuracy: 0.5191, Val F1: 0.6243\n",
      "Checkpoint saved at epoch 40.\n",
      "Starting epoch 41/100...\n",
      "Epoch 41, Train Loss: 0.2607, Accuracy: 0.5986, F1 Score: 0.7556\n",
      "Epoch 41, Val Loss: 0.4483, Val Accuracy: 0.5182, Val F1: 0.6163\n",
      "Checkpoint saved at epoch 41.\n",
      "Starting epoch 42/100...\n",
      "Epoch 42, Train Loss: 0.2538, Accuracy: 0.6138, F1 Score: 0.7691\n",
      "Epoch 42, Val Loss: 0.4534, Val Accuracy: 0.5112, Val F1: 0.6234\n",
      "Checkpoint saved at epoch 42.\n",
      "Starting epoch 43/100...\n",
      "Epoch 43, Train Loss: 0.2467, Accuracy: 0.6203, F1 Score: 0.7769\n",
      "Epoch 43, Val Loss: 0.4617, Val Accuracy: 0.5042, Val F1: 0.6087\n",
      "Checkpoint saved at epoch 43.\n",
      "Starting epoch 44/100...\n",
      "Epoch 44, Train Loss: 0.2432, Accuracy: 0.6247, F1 Score: 0.7814\n",
      "Epoch 44, Val Loss: 0.4640, Val Accuracy: 0.5033, Val F1: 0.6254\n",
      "Checkpoint saved at epoch 44.\n",
      "Starting epoch 45/100...\n",
      "Epoch 45, Train Loss: 0.2410, Accuracy: 0.6228, F1 Score: 0.7797\n",
      "Epoch 45, Val Loss: 0.4737, Val Accuracy: 0.5247, Val F1: 0.6061\n",
      "Checkpoint saved at epoch 45.\n",
      "Starting epoch 46/100...\n",
      "Epoch 46, Train Loss: 0.2344, Accuracy: 0.6308, F1 Score: 0.7901\n",
      "Epoch 46, Val Loss: 0.4751, Val Accuracy: 0.5172, Val F1: 0.6108\n",
      "Checkpoint saved at epoch 46.\n",
      "Starting epoch 47/100...\n",
      "Epoch 47, Train Loss: 0.2313, Accuracy: 0.6373, F1 Score: 0.7944\n",
      "Epoch 47, Val Loss: 0.4993, Val Accuracy: 0.5107, Val F1: 0.5987\n",
      "Checkpoint saved at epoch 47.\n",
      "Starting epoch 48/100...\n",
      "Epoch 48, Train Loss: 0.2235, Accuracy: 0.6398, F1 Score: 0.7998\n",
      "Epoch 48, Val Loss: 0.5071, Val Accuracy: 0.5014, Val F1: 0.6159\n",
      "Checkpoint saved at epoch 48.\n",
      "Starting epoch 49/100...\n",
      "Epoch 49, Train Loss: 0.2178, Accuracy: 0.6563, F1 Score: 0.8093\n",
      "Epoch 49, Val Loss: 0.5129, Val Accuracy: 0.5056, Val F1: 0.6113\n",
      "Checkpoint saved at epoch 49.\n",
      "Starting epoch 50/100...\n",
      "Epoch 50, Train Loss: 0.2162, Accuracy: 0.6601, F1 Score: 0.8100\n",
      "Epoch 50, Val Loss: 0.5247, Val Accuracy: 0.5149, Val F1: 0.5992\n",
      "Checkpoint saved at epoch 50.\n",
      "Starting epoch 51/100...\n",
      "Epoch 51, Train Loss: 0.2094, Accuracy: 0.6634, F1 Score: 0.8166\n",
      "Epoch 51, Val Loss: 0.5538, Val Accuracy: 0.5140, Val F1: 0.6125\n",
      "Checkpoint saved at epoch 51.\n",
      "Starting epoch 52/100...\n",
      "Epoch 52, Train Loss: 0.2085, Accuracy: 0.6667, F1 Score: 0.8193\n",
      "Epoch 52, Val Loss: 0.5530, Val Accuracy: 0.5130, Val F1: 0.6137\n",
      "Checkpoint saved at epoch 52.\n",
      "Starting epoch 53/100...\n",
      "Epoch 53, Train Loss: 0.2055, Accuracy: 0.6693, F1 Score: 0.8234\n",
      "Epoch 53, Val Loss: 0.5535, Val Accuracy: 0.5191, Val F1: 0.6127\n",
      "Checkpoint saved at epoch 53.\n",
      "Starting epoch 54/100...\n",
      "Epoch 54, Train Loss: 0.1998, Accuracy: 0.6765, F1 Score: 0.8284\n",
      "Epoch 54, Val Loss: 0.5829, Val Accuracy: 0.4921, Val F1: 0.6013\n",
      "Checkpoint saved at epoch 54.\n",
      "Starting epoch 55/100...\n",
      "Epoch 55, Train Loss: 0.1950, Accuracy: 0.6821, F1 Score: 0.8330\n",
      "Epoch 55, Val Loss: 0.5830, Val Accuracy: 0.5014, Val F1: 0.5975\n",
      "Checkpoint saved at epoch 55.\n",
      "Starting epoch 56/100...\n",
      "Epoch 56, Train Loss: 0.2011, Accuracy: 0.6759, F1 Score: 0.8285\n",
      "Epoch 56, Val Loss: 0.5714, Val Accuracy: 0.4916, Val F1: 0.6145\n",
      "Starting epoch 57/100...\n",
      "Epoch 57, Train Loss: 0.1913, Accuracy: 0.6867, F1 Score: 0.8380\n",
      "Epoch 57, Val Loss: 0.6051, Val Accuracy: 0.5158, Val F1: 0.6053\n",
      "Checkpoint saved at epoch 57.\n",
      "Starting epoch 58/100...\n",
      "Epoch 58, Train Loss: 0.1910, Accuracy: 0.6885, F1 Score: 0.8383\n",
      "Epoch 58, Val Loss: 0.6064, Val Accuracy: 0.5200, Val F1: 0.6167\n",
      "Checkpoint saved at epoch 58.\n",
      "Starting epoch 59/100...\n",
      "Epoch 59, Train Loss: 0.1892, Accuracy: 0.6895, F1 Score: 0.8393\n",
      "Epoch 59, Val Loss: 0.6168, Val Accuracy: 0.5130, Val F1: 0.6114\n",
      "Checkpoint saved at epoch 59.\n",
      "Starting epoch 60/100...\n",
      "Epoch 60, Train Loss: 0.1816, Accuracy: 0.6968, F1 Score: 0.8475\n",
      "Epoch 60, Val Loss: 0.6614, Val Accuracy: 0.5098, Val F1: 0.6143\n",
      "Checkpoint saved at epoch 60.\n",
      "Starting epoch 61/100...\n",
      "Epoch 61, Train Loss: 0.1865, Accuracy: 0.6956, F1 Score: 0.8443\n",
      "Epoch 61, Val Loss: 0.6430, Val Accuracy: 0.5000, Val F1: 0.6042\n",
      "Starting epoch 62/100...\n",
      "Epoch 62, Train Loss: 0.1777, Accuracy: 0.7024, F1 Score: 0.8523\n",
      "Epoch 62, Val Loss: 0.6660, Val Accuracy: 0.4856, Val F1: 0.6105\n",
      "Checkpoint saved at epoch 62.\n",
      "Starting epoch 63/100...\n",
      "Epoch 63, Train Loss: 0.1883, Accuracy: 0.6885, F1 Score: 0.8407\n",
      "Epoch 63, Val Loss: 0.6266, Val Accuracy: 0.5242, Val F1: 0.6109\n",
      "Starting epoch 64/100...\n",
      "Epoch 64, Train Loss: 0.1741, Accuracy: 0.7134, F1 Score: 0.8577\n",
      "Epoch 64, Val Loss: 0.6421, Val Accuracy: 0.5079, Val F1: 0.6251\n",
      "Checkpoint saved at epoch 64.\n",
      "Starting epoch 65/100...\n",
      "Epoch 65, Train Loss: 0.1768, Accuracy: 0.7116, F1 Score: 0.8544\n",
      "Epoch 65, Val Loss: 0.6635, Val Accuracy: 0.4944, Val F1: 0.5932\n",
      "Starting epoch 66/100...\n",
      "Epoch 66, Train Loss: 0.1778, Accuracy: 0.7036, F1 Score: 0.8530\n",
      "Epoch 66, Val Loss: 0.6667, Val Accuracy: 0.5135, Val F1: 0.6175\n",
      "Starting epoch 67/100...\n",
      "Epoch 67, Train Loss: 0.1746, Accuracy: 0.7046, F1 Score: 0.8572\n",
      "Epoch 67, Val Loss: 0.6771, Val Accuracy: 0.4683, Val F1: 0.6103\n",
      "Starting epoch 68/100...\n",
      "Epoch 68, Train Loss: 0.1738, Accuracy: 0.7070, F1 Score: 0.8558\n",
      "Epoch 68, Val Loss: 0.6639, Val Accuracy: 0.5103, Val F1: 0.6204\n",
      "Checkpoint saved at epoch 68.\n",
      "Starting epoch 69/100...\n",
      "Epoch 69, Train Loss: 0.1728, Accuracy: 0.7110, F1 Score: 0.8583\n",
      "Epoch 69, Val Loss: 0.6915, Val Accuracy: 0.5037, Val F1: 0.6011\n",
      "Checkpoint saved at epoch 69.\n",
      "Starting epoch 70/100...\n",
      "Epoch 70, Train Loss: 0.1738, Accuracy: 0.7098, F1 Score: 0.8557\n",
      "Epoch 70, Val Loss: 0.7014, Val Accuracy: 0.5028, Val F1: 0.5999\n",
      "Starting epoch 71/100...\n",
      "Epoch 71, Train Loss: 0.1627, Accuracy: 0.7313, F1 Score: 0.8704\n",
      "Epoch 71, Val Loss: 0.7109, Val Accuracy: 0.4977, Val F1: 0.6189\n",
      "Checkpoint saved at epoch 71.\n",
      "Starting epoch 72/100...\n",
      "Epoch 72, Train Loss: 0.1717, Accuracy: 0.7173, F1 Score: 0.8617\n",
      "Epoch 72, Val Loss: 0.7341, Val Accuracy: 0.4963, Val F1: 0.6031\n",
      "Starting epoch 73/100...\n",
      "Epoch 73, Train Loss: 0.1668, Accuracy: 0.7155, F1 Score: 0.8622\n",
      "Epoch 73, Val Loss: 0.7351, Val Accuracy: 0.5042, Val F1: 0.6089\n",
      "Starting epoch 74/100...\n",
      "Epoch 74, Train Loss: 0.1589, Accuracy: 0.7305, F1 Score: 0.8718\n",
      "Epoch 74, Val Loss: 0.8121, Val Accuracy: 0.4995, Val F1: 0.6028\n",
      "Checkpoint saved at epoch 74.\n",
      "Starting epoch 75/100...\n",
      "Epoch 75, Train Loss: 0.1790, Accuracy: 0.7003, F1 Score: 0.8515\n",
      "Epoch 75, Val Loss: 0.7289, Val Accuracy: 0.5019, Val F1: 0.5993\n",
      "Starting epoch 76/100...\n",
      "Epoch 76, Train Loss: 0.1700, Accuracy: 0.7165, F1 Score: 0.8621\n",
      "Epoch 76, Val Loss: 0.7211, Val Accuracy: 0.4939, Val F1: 0.6215\n",
      "Starting epoch 77/100...\n",
      "Epoch 77, Train Loss: 0.1639, Accuracy: 0.7208, F1 Score: 0.8646\n",
      "Epoch 77, Val Loss: 0.7400, Val Accuracy: 0.4907, Val F1: 0.6164\n",
      "Starting epoch 78/100...\n",
      "Epoch 78, Train Loss: 0.1631, Accuracy: 0.7242, F1 Score: 0.8678\n",
      "Epoch 78, Val Loss: 0.7500, Val Accuracy: 0.5028, Val F1: 0.6139\n",
      "Starting epoch 79/100...\n",
      "Epoch 79, Train Loss: 0.1626, Accuracy: 0.7245, F1 Score: 0.8685\n",
      "Epoch 79, Val Loss: 0.7692, Val Accuracy: 0.5023, Val F1: 0.6058\n",
      "Early stopping triggered after 79 epochs.\n",
      "Best model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_177267/2188939409.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    }
   ],
   "source": [
    "from timm.models import deit_tiny_distilled_patch16_224\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDeiT_tiny(nn.Module):\n",
    "    def __init__(self, pretrained=False, num_classes=5, drop_rate=0.2):\n",
    "        super(CustomDeiT_tiny, self).__init__()\n",
    "        self.model = deit_tiny_distilled_patch16_224(pretrained=pretrained, num_classes=num_classes)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.model(x)\n",
    "        if isinstance(outputs, tuple):\n",
    "            x1, x2 = outputs\n",
    "            avg_output = (x1 + x2) / 2\n",
    "        else:\n",
    "            avg_output = outputs\n",
    "\n",
    "        return self.dropout(avg_output)\n",
    "\n",
    "deit_tiny_model = CustomDeiT_tiny(pretrained=False, num_classes=5, drop_rate=0.2).to(device)\n",
    "\n",
    "logs_tiny = train_model(\n",
    "    model=deit_tiny_model,\n",
    "    train_loader=train_loader,  # 제공된 학습 데이터 로더\n",
    "    val_loader=val_loader,      # 제공된 검증 데이터 로더\n",
    "    num_epochs=100,              # 총 학습 epoch 수\n",
    "    patience=5,                 # 조기 종료를 위한 patience\n",
    "    learning_rate=0.0001,       # 최적 학습률\n",
    "    checkpoint_path='best_deit_tiny_model.pth'  # 체크포인트 저장 경로\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0j6Sen1FKur",
    "outputId": "c8d4c9ad-5d64-44bc-cc60-503f87679a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Loss: 0.8121\n",
      "Validation Accuracy: 0.4995\n",
      "Validation F1 Score: 0.6028\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.8141\n",
      "Test Accuracy: 0.4884\n",
      "Test F1 Score: 0.5955\n"
     ]
    }
   ],
   "source": [
    "validation_loader = DataLoader(\n",
    "    ECGDataset(X_val, y_val_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_loss, val_accuracy, val_f1 = evaluate_model(deit_tiny_model, validation_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_loader = DataLoader(\n",
    "    ECGDataset(X_test, y_test_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_accuracy, test_f1 = evaluate_model(deit_tiny_model, test_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mo0AD04GMpdn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100...\n",
      "Epoch 1, Train Loss: 0.5447, Accuracy: 0.2016, F1 Score: 0.2109\n",
      "Epoch 1, Val Loss: 0.4553, Val Accuracy: 0.3388, Val F1: 0.3649\n",
      "Checkpoint saved at epoch 1.\n",
      "Starting epoch 2/100...\n",
      "Epoch 2, Train Loss: 0.4851, Accuracy: 0.3234, F1 Score: 0.3867\n",
      "Epoch 2, Val Loss: 0.4153, Val Accuracy: 0.4380, Val F1: 0.4802\n",
      "Checkpoint saved at epoch 2.\n",
      "Starting epoch 3/100...\n",
      "Epoch 3, Train Loss: 0.4700, Accuracy: 0.3416, F1 Score: 0.4280\n",
      "Epoch 3, Val Loss: 0.4108, Val Accuracy: 0.4669, Val F1: 0.5290\n",
      "Checkpoint saved at epoch 3.\n",
      "Starting epoch 4/100...\n",
      "Epoch 4, Train Loss: 0.4585, Accuracy: 0.3565, F1 Score: 0.4594\n",
      "Epoch 4, Val Loss: 0.3980, Val Accuracy: 0.4716, Val F1: 0.5598\n",
      "Checkpoint saved at epoch 4.\n",
      "Starting epoch 5/100...\n",
      "Epoch 5, Train Loss: 0.4519, Accuracy: 0.3702, F1 Score: 0.4776\n",
      "Epoch 5, Val Loss: 0.3913, Val Accuracy: 0.4949, Val F1: 0.5261\n",
      "Checkpoint saved at epoch 5.\n",
      "Starting epoch 6/100...\n",
      "Epoch 6, Train Loss: 0.4483, Accuracy: 0.3775, F1 Score: 0.4860\n",
      "Epoch 6, Val Loss: 0.3919, Val Accuracy: 0.4720, Val F1: 0.5345\n",
      "Checkpoint saved at epoch 6.\n",
      "Starting epoch 7/100...\n",
      "Epoch 7, Train Loss: 0.4417, Accuracy: 0.3819, F1 Score: 0.4998\n",
      "Epoch 7, Val Loss: 0.3845, Val Accuracy: 0.4893, Val F1: 0.5330\n",
      "Checkpoint saved at epoch 7.\n",
      "Starting epoch 8/100...\n",
      "Epoch 8, Train Loss: 0.4392, Accuracy: 0.3828, F1 Score: 0.5008\n",
      "Epoch 8, Val Loss: 0.3869, Val Accuracy: 0.4623, Val F1: 0.5095\n",
      "Checkpoint saved at epoch 8.\n",
      "Starting epoch 9/100...\n",
      "Epoch 9, Train Loss: 0.4365, Accuracy: 0.3910, F1 Score: 0.5149\n",
      "Epoch 9, Val Loss: 0.3909, Val Accuracy: 0.4888, Val F1: 0.5099\n",
      "Checkpoint saved at epoch 9.\n",
      "Starting epoch 10/100...\n",
      "Epoch 10, Train Loss: 0.4323, Accuracy: 0.3910, F1 Score: 0.5126\n",
      "Epoch 10, Val Loss: 0.3774, Val Accuracy: 0.4921, Val F1: 0.5604\n",
      "Checkpoint saved at epoch 10.\n",
      "Starting epoch 11/100...\n",
      "Epoch 11, Train Loss: 0.4310, Accuracy: 0.3983, F1 Score: 0.5202\n",
      "Epoch 11, Val Loss: 0.3769, Val Accuracy: 0.4972, Val F1: 0.5853\n",
      "Checkpoint saved at epoch 11.\n",
      "Starting epoch 12/100...\n",
      "Epoch 12, Train Loss: 0.4267, Accuracy: 0.3979, F1 Score: 0.5230\n",
      "Epoch 12, Val Loss: 0.3803, Val Accuracy: 0.4706, Val F1: 0.5089\n",
      "Checkpoint saved at epoch 12.\n",
      "Starting epoch 13/100...\n",
      "Epoch 13, Train Loss: 0.4243, Accuracy: 0.4075, F1 Score: 0.5333\n",
      "Epoch 13, Val Loss: 0.3757, Val Accuracy: 0.5028, Val F1: 0.6005\n",
      "Checkpoint saved at epoch 13.\n",
      "Starting epoch 14/100...\n",
      "Epoch 14, Train Loss: 0.4220, Accuracy: 0.4035, F1 Score: 0.5351\n",
      "Epoch 14, Val Loss: 0.3752, Val Accuracy: 0.4823, Val F1: 0.5861\n",
      "Checkpoint saved at epoch 14.\n",
      "Starting epoch 15/100...\n",
      "Epoch 15, Train Loss: 0.4190, Accuracy: 0.4086, F1 Score: 0.5410\n",
      "Epoch 15, Val Loss: 0.3751, Val Accuracy: 0.4664, Val F1: 0.5621\n",
      "Checkpoint saved at epoch 15.\n",
      "Starting epoch 16/100...\n",
      "Epoch 16, Train Loss: 0.4178, Accuracy: 0.4153, F1 Score: 0.5449\n",
      "Epoch 16, Val Loss: 0.3789, Val Accuracy: 0.4790, Val F1: 0.5363\n",
      "Checkpoint saved at epoch 16.\n",
      "Starting epoch 17/100...\n",
      "Epoch 17, Train Loss: 0.4151, Accuracy: 0.4180, F1 Score: 0.5471\n",
      "Epoch 17, Val Loss: 0.3756, Val Accuracy: 0.4907, Val F1: 0.5514\n",
      "Checkpoint saved at epoch 17.\n",
      "Starting epoch 18/100...\n",
      "Epoch 18, Train Loss: 0.4147, Accuracy: 0.4246, F1 Score: 0.5554\n",
      "Epoch 18, Val Loss: 0.3757, Val Accuracy: 0.4977, Val F1: 0.6041\n",
      "Checkpoint saved at epoch 18.\n",
      "Starting epoch 19/100...\n",
      "Epoch 19, Train Loss: 0.4090, Accuracy: 0.4224, F1 Score: 0.5541\n",
      "Epoch 19, Val Loss: 0.3655, Val Accuracy: 0.5098, Val F1: 0.5804\n",
      "Checkpoint saved at epoch 19.\n",
      "Starting epoch 20/100...\n",
      "Epoch 20, Train Loss: 0.4065, Accuracy: 0.4242, F1 Score: 0.5603\n",
      "Epoch 20, Val Loss: 0.3598, Val Accuracy: 0.5158, Val F1: 0.6087\n",
      "Checkpoint saved at epoch 20.\n",
      "Starting epoch 21/100...\n",
      "Epoch 21, Train Loss: 0.4051, Accuracy: 0.4310, F1 Score: 0.5650\n",
      "Epoch 21, Val Loss: 0.3658, Val Accuracy: 0.5112, Val F1: 0.6160\n",
      "Checkpoint saved at epoch 21.\n",
      "Starting epoch 22/100...\n",
      "Epoch 22, Train Loss: 0.4049, Accuracy: 0.4292, F1 Score: 0.5699\n",
      "Epoch 22, Val Loss: 0.3700, Val Accuracy: 0.5126, Val F1: 0.5666\n",
      "Checkpoint saved at epoch 22.\n",
      "Starting epoch 23/100...\n",
      "Epoch 23, Train Loss: 0.4024, Accuracy: 0.4357, F1 Score: 0.5717\n",
      "Epoch 23, Val Loss: 0.3660, Val Accuracy: 0.4995, Val F1: 0.6133\n",
      "Checkpoint saved at epoch 23.\n",
      "Starting epoch 24/100...\n",
      "Epoch 24, Train Loss: 0.3981, Accuracy: 0.4389, F1 Score: 0.5763\n",
      "Epoch 24, Val Loss: 0.3704, Val Accuracy: 0.4907, Val F1: 0.5530\n",
      "Checkpoint saved at epoch 24.\n",
      "Starting epoch 25/100...\n",
      "Epoch 25, Train Loss: 0.3975, Accuracy: 0.4371, F1 Score: 0.5749\n",
      "Epoch 25, Val Loss: 0.3643, Val Accuracy: 0.4958, Val F1: 0.5763\n",
      "Checkpoint saved at epoch 25.\n",
      "Starting epoch 26/100...\n",
      "Epoch 26, Train Loss: 0.3988, Accuracy: 0.4363, F1 Score: 0.5795\n",
      "Epoch 26, Val Loss: 0.3609, Val Accuracy: 0.5308, Val F1: 0.6278\n",
      "Starting epoch 27/100...\n",
      "Epoch 27, Train Loss: 0.3957, Accuracy: 0.4400, F1 Score: 0.5769\n",
      "Epoch 27, Val Loss: 0.3671, Val Accuracy: 0.4958, Val F1: 0.6256\n",
      "Checkpoint saved at epoch 27.\n",
      "Starting epoch 28/100...\n",
      "Epoch 28, Train Loss: 0.3949, Accuracy: 0.4409, F1 Score: 0.5773\n",
      "Epoch 28, Val Loss: 0.3618, Val Accuracy: 0.5075, Val F1: 0.5759\n",
      "Checkpoint saved at epoch 28.\n",
      "Starting epoch 29/100...\n",
      "Epoch 29, Train Loss: 0.3925, Accuracy: 0.4431, F1 Score: 0.5848\n",
      "Epoch 29, Val Loss: 0.3638, Val Accuracy: 0.5112, Val F1: 0.6329\n",
      "Checkpoint saved at epoch 29.\n",
      "Starting epoch 30/100...\n",
      "Epoch 30, Train Loss: 0.3922, Accuracy: 0.4453, F1 Score: 0.5847\n",
      "Epoch 30, Val Loss: 0.3660, Val Accuracy: 0.4772, Val F1: 0.6163\n",
      "Checkpoint saved at epoch 30.\n",
      "Starting epoch 31/100...\n",
      "Epoch 31, Train Loss: 0.3903, Accuracy: 0.4470, F1 Score: 0.5877\n",
      "Epoch 31, Val Loss: 0.3629, Val Accuracy: 0.5103, Val F1: 0.5947\n",
      "Checkpoint saved at epoch 31.\n",
      "Starting epoch 32/100...\n",
      "Epoch 32, Train Loss: 0.3879, Accuracy: 0.4508, F1 Score: 0.5951\n",
      "Epoch 32, Val Loss: 0.3676, Val Accuracy: 0.4958, Val F1: 0.6035\n",
      "Checkpoint saved at epoch 32.\n",
      "Starting epoch 33/100...\n",
      "Epoch 33, Train Loss: 0.3884, Accuracy: 0.4437, F1 Score: 0.5859\n",
      "Epoch 33, Val Loss: 0.3627, Val Accuracy: 0.5126, Val F1: 0.5973\n",
      "Starting epoch 34/100...\n",
      "Epoch 34, Train Loss: 0.3861, Accuracy: 0.4505, F1 Score: 0.5872\n",
      "Epoch 34, Val Loss: 0.3598, Val Accuracy: 0.5163, Val F1: 0.6364\n",
      "Checkpoint saved at epoch 34.\n",
      "Starting epoch 35/100...\n",
      "Epoch 35, Train Loss: 0.3857, Accuracy: 0.4549, F1 Score: 0.5997\n",
      "Epoch 35, Val Loss: 0.3658, Val Accuracy: 0.5065, Val F1: 0.6025\n",
      "Checkpoint saved at epoch 35.\n",
      "Starting epoch 36/100...\n",
      "Epoch 36, Train Loss: 0.3843, Accuracy: 0.4534, F1 Score: 0.5993\n",
      "Epoch 36, Val Loss: 0.3673, Val Accuracy: 0.5144, Val F1: 0.6079\n",
      "Checkpoint saved at epoch 36.\n",
      "Starting epoch 37/100...\n",
      "Epoch 37, Train Loss: 0.3803, Accuracy: 0.4648, F1 Score: 0.6035\n",
      "Epoch 37, Val Loss: 0.3683, Val Accuracy: 0.5121, Val F1: 0.6272\n",
      "Checkpoint saved at epoch 37.\n",
      "Starting epoch 38/100...\n",
      "Epoch 38, Train Loss: 0.3805, Accuracy: 0.4598, F1 Score: 0.6044\n",
      "Epoch 38, Val Loss: 0.3632, Val Accuracy: 0.5005, Val F1: 0.5925\n",
      "Starting epoch 39/100...\n",
      "Epoch 39, Train Loss: 0.3747, Accuracy: 0.4647, F1 Score: 0.6103\n",
      "Epoch 39, Val Loss: 0.3672, Val Accuracy: 0.5014, Val F1: 0.6322\n",
      "Checkpoint saved at epoch 39.\n",
      "Starting epoch 40/100...\n",
      "Epoch 40, Train Loss: 0.3749, Accuracy: 0.4718, F1 Score: 0.6156\n",
      "Epoch 40, Val Loss: 0.3605, Val Accuracy: 0.5056, Val F1: 0.6059\n",
      "Starting epoch 41/100...\n",
      "Epoch 41, Train Loss: 0.3731, Accuracy: 0.4689, F1 Score: 0.6160\n",
      "Epoch 41, Val Loss: 0.3602, Val Accuracy: 0.5214, Val F1: 0.6067\n",
      "Checkpoint saved at epoch 41.\n",
      "Starting epoch 42/100...\n",
      "Epoch 42, Train Loss: 0.3755, Accuracy: 0.4625, F1 Score: 0.6097\n",
      "Epoch 42, Val Loss: 0.3610, Val Accuracy: 0.5056, Val F1: 0.6085\n",
      "Starting epoch 43/100...\n",
      "Epoch 43, Train Loss: 0.3719, Accuracy: 0.4730, F1 Score: 0.6196\n",
      "Epoch 43, Val Loss: 0.3614, Val Accuracy: 0.5196, Val F1: 0.6282\n",
      "Checkpoint saved at epoch 43.\n",
      "Starting epoch 44/100...\n",
      "Epoch 44, Train Loss: 0.3704, Accuracy: 0.4700, F1 Score: 0.6193\n",
      "Epoch 44, Val Loss: 0.3645, Val Accuracy: 0.5070, Val F1: 0.6163\n",
      "Checkpoint saved at epoch 44.\n",
      "Starting epoch 45/100...\n",
      "Epoch 45, Train Loss: 0.3700, Accuracy: 0.4729, F1 Score: 0.6193\n",
      "Epoch 45, Val Loss: 0.3605, Val Accuracy: 0.5210, Val F1: 0.6130\n",
      "Checkpoint saved at epoch 45.\n",
      "Starting epoch 46/100...\n",
      "Epoch 46, Train Loss: 0.3668, Accuracy: 0.4731, F1 Score: 0.6252\n",
      "Epoch 46, Val Loss: 0.3616, Val Accuracy: 0.5144, Val F1: 0.6274\n",
      "Checkpoint saved at epoch 46.\n",
      "Starting epoch 47/100...\n",
      "Epoch 47, Train Loss: 0.3690, Accuracy: 0.4731, F1 Score: 0.6252\n",
      "Epoch 47, Val Loss: 0.3659, Val Accuracy: 0.5107, Val F1: 0.6155\n",
      "Starting epoch 48/100...\n",
      "Epoch 48, Train Loss: 0.3663, Accuracy: 0.4762, F1 Score: 0.6240\n",
      "Epoch 48, Val Loss: 0.3648, Val Accuracy: 0.5089, Val F1: 0.6263\n",
      "Checkpoint saved at epoch 48.\n",
      "Starting epoch 49/100...\n",
      "Epoch 49, Train Loss: 0.3649, Accuracy: 0.4762, F1 Score: 0.6280\n",
      "Epoch 49, Val Loss: 0.3664, Val Accuracy: 0.5214, Val F1: 0.6024\n",
      "Checkpoint saved at epoch 49.\n",
      "Starting epoch 50/100...\n",
      "Epoch 50, Train Loss: 0.3620, Accuracy: 0.4811, F1 Score: 0.6309\n",
      "Epoch 50, Val Loss: 0.3658, Val Accuracy: 0.5200, Val F1: 0.6313\n",
      "Checkpoint saved at epoch 50.\n",
      "Starting epoch 51/100...\n",
      "Epoch 51, Train Loss: 0.3632, Accuracy: 0.4819, F1 Score: 0.6298\n",
      "Epoch 51, Val Loss: 0.3630, Val Accuracy: 0.5130, Val F1: 0.6299\n",
      "Starting epoch 52/100...\n",
      "Epoch 52, Train Loss: 0.3565, Accuracy: 0.4871, F1 Score: 0.6370\n",
      "Epoch 52, Val Loss: 0.3628, Val Accuracy: 0.5205, Val F1: 0.6221\n",
      "Checkpoint saved at epoch 52.\n",
      "Starting epoch 53/100...\n",
      "Epoch 53, Train Loss: 0.3595, Accuracy: 0.4823, F1 Score: 0.6357\n",
      "Epoch 53, Val Loss: 0.3668, Val Accuracy: 0.5005, Val F1: 0.6132\n",
      "Starting epoch 54/100...\n",
      "Epoch 54, Train Loss: 0.3580, Accuracy: 0.4844, F1 Score: 0.6353\n",
      "Epoch 54, Val Loss: 0.3714, Val Accuracy: 0.5247, Val F1: 0.6335\n",
      "Starting epoch 55/100...\n",
      "Epoch 55, Train Loss: 0.3559, Accuracy: 0.4888, F1 Score: 0.6401\n",
      "Epoch 55, Val Loss: 0.3701, Val Accuracy: 0.5154, Val F1: 0.6222\n",
      "Checkpoint saved at epoch 55.\n",
      "Starting epoch 56/100...\n",
      "Epoch 56, Train Loss: 0.3520, Accuracy: 0.4908, F1 Score: 0.6407\n",
      "Epoch 56, Val Loss: 0.3622, Val Accuracy: 0.5172, Val F1: 0.6011\n",
      "Checkpoint saved at epoch 56.\n",
      "Starting epoch 57/100...\n",
      "Epoch 57, Train Loss: 0.3532, Accuracy: 0.4845, F1 Score: 0.6411\n",
      "Epoch 57, Val Loss: 0.3655, Val Accuracy: 0.5103, Val F1: 0.6061\n",
      "Starting epoch 58/100...\n",
      "Epoch 58, Train Loss: 0.3499, Accuracy: 0.4895, F1 Score: 0.6484\n",
      "Epoch 58, Val Loss: 0.3726, Val Accuracy: 0.5177, Val F1: 0.6021\n",
      "Checkpoint saved at epoch 58.\n",
      "Starting epoch 59/100...\n",
      "Epoch 59, Train Loss: 0.3471, Accuracy: 0.4940, F1 Score: 0.6488\n",
      "Epoch 59, Val Loss: 0.3719, Val Accuracy: 0.5075, Val F1: 0.6006\n",
      "Checkpoint saved at epoch 59.\n",
      "Starting epoch 60/100...\n",
      "Epoch 60, Train Loss: 0.3451, Accuracy: 0.4945, F1 Score: 0.6481\n",
      "Epoch 60, Val Loss: 0.3708, Val Accuracy: 0.4981, Val F1: 0.6172\n",
      "Checkpoint saved at epoch 60.\n",
      "Starting epoch 61/100...\n",
      "Epoch 61, Train Loss: 0.3447, Accuracy: 0.5000, F1 Score: 0.6616\n",
      "Epoch 61, Val Loss: 0.3813, Val Accuracy: 0.5079, Val F1: 0.6147\n",
      "Checkpoint saved at epoch 61.\n",
      "Starting epoch 62/100...\n",
      "Epoch 62, Train Loss: 0.3419, Accuracy: 0.5028, F1 Score: 0.6631\n",
      "Epoch 62, Val Loss: 0.3755, Val Accuracy: 0.5200, Val F1: 0.6218\n",
      "Checkpoint saved at epoch 62.\n",
      "Starting epoch 63/100...\n",
      "Epoch 63, Train Loss: 0.3387, Accuracy: 0.5034, F1 Score: 0.6638\n",
      "Epoch 63, Val Loss: 0.3809, Val Accuracy: 0.5070, Val F1: 0.6229\n",
      "Checkpoint saved at epoch 63.\n",
      "Starting epoch 64/100...\n",
      "Epoch 64, Train Loss: 0.3372, Accuracy: 0.5094, F1 Score: 0.6669\n",
      "Epoch 64, Val Loss: 0.3907, Val Accuracy: 0.4702, Val F1: 0.6049\n",
      "Checkpoint saved at epoch 64.\n",
      "Starting epoch 65/100...\n",
      "Epoch 65, Train Loss: 0.3336, Accuracy: 0.5135, F1 Score: 0.6741\n",
      "Epoch 65, Val Loss: 0.3748, Val Accuracy: 0.5252, Val F1: 0.6116\n",
      "Checkpoint saved at epoch 65.\n",
      "Starting epoch 66/100...\n",
      "Epoch 66, Train Loss: 0.3338, Accuracy: 0.5066, F1 Score: 0.6680\n",
      "Epoch 66, Val Loss: 0.3791, Val Accuracy: 0.5005, Val F1: 0.6000\n",
      "Starting epoch 67/100...\n",
      "Epoch 67, Train Loss: 0.3316, Accuracy: 0.5136, F1 Score: 0.6739\n",
      "Epoch 67, Val Loss: 0.3830, Val Accuracy: 0.5130, Val F1: 0.6198\n",
      "Checkpoint saved at epoch 67.\n",
      "Starting epoch 68/100...\n",
      "Epoch 68, Train Loss: 0.3270, Accuracy: 0.5219, F1 Score: 0.6824\n",
      "Epoch 68, Val Loss: 0.3810, Val Accuracy: 0.5177, Val F1: 0.5981\n",
      "Checkpoint saved at epoch 68.\n",
      "Starting epoch 69/100...\n",
      "Epoch 69, Train Loss: 0.3269, Accuracy: 0.5156, F1 Score: 0.6786\n",
      "Epoch 69, Val Loss: 0.3819, Val Accuracy: 0.5051, Val F1: 0.6290\n",
      "Checkpoint saved at epoch 69.\n",
      "Starting epoch 70/100...\n",
      "Epoch 70, Train Loss: 0.3229, Accuracy: 0.5266, F1 Score: 0.6867\n",
      "Epoch 70, Val Loss: 0.3818, Val Accuracy: 0.4963, Val F1: 0.6242\n",
      "Checkpoint saved at epoch 70.\n",
      "Starting epoch 71/100...\n",
      "Epoch 71, Train Loss: 0.3207, Accuracy: 0.5307, F1 Score: 0.6868\n",
      "Epoch 71, Val Loss: 0.3966, Val Accuracy: 0.4949, Val F1: 0.6117\n",
      "Checkpoint saved at epoch 71.\n",
      "Starting epoch 72/100...\n",
      "Epoch 72, Train Loss: 0.3149, Accuracy: 0.5278, F1 Score: 0.6933\n",
      "Epoch 72, Val Loss: 0.3923, Val Accuracy: 0.4991, Val F1: 0.5966\n",
      "Checkpoint saved at epoch 72.\n",
      "Starting epoch 73/100...\n",
      "Epoch 73, Train Loss: 0.3132, Accuracy: 0.5340, F1 Score: 0.6975\n",
      "Epoch 73, Val Loss: 0.3929, Val Accuracy: 0.5098, Val F1: 0.6133\n",
      "Checkpoint saved at epoch 73.\n",
      "Starting epoch 74/100...\n",
      "Epoch 74, Train Loss: 0.3089, Accuracy: 0.5406, F1 Score: 0.7028\n",
      "Epoch 74, Val Loss: 0.3957, Val Accuracy: 0.5270, Val F1: 0.6146\n",
      "Checkpoint saved at epoch 74.\n",
      "Starting epoch 75/100...\n",
      "Epoch 75, Train Loss: 0.3046, Accuracy: 0.5447, F1 Score: 0.7095\n",
      "Epoch 75, Val Loss: 0.4213, Val Accuracy: 0.5000, Val F1: 0.6233\n",
      "Checkpoint saved at epoch 75.\n",
      "Starting epoch 76/100...\n",
      "Epoch 76, Train Loss: 0.2993, Accuracy: 0.5505, F1 Score: 0.7160\n",
      "Epoch 76, Val Loss: 0.4001, Val Accuracy: 0.5033, Val F1: 0.6131\n",
      "Checkpoint saved at epoch 76.\n",
      "Starting epoch 77/100...\n",
      "Epoch 77, Train Loss: 0.2951, Accuracy: 0.5497, F1 Score: 0.7179\n",
      "Epoch 77, Val Loss: 0.4252, Val Accuracy: 0.5005, Val F1: 0.6104\n",
      "Checkpoint saved at epoch 77.\n",
      "Starting epoch 78/100...\n",
      "Epoch 78, Train Loss: 0.2969, Accuracy: 0.5547, F1 Score: 0.7207\n",
      "Epoch 78, Val Loss: 0.4145, Val Accuracy: 0.4949, Val F1: 0.6126\n",
      "Starting epoch 79/100...\n",
      "Epoch 79, Train Loss: 0.2885, Accuracy: 0.5606, F1 Score: 0.7258\n",
      "Epoch 79, Val Loss: 0.4274, Val Accuracy: 0.4828, Val F1: 0.5948\n",
      "Checkpoint saved at epoch 79.\n",
      "Starting epoch 80/100...\n",
      "Epoch 80, Train Loss: 0.2867, Accuracy: 0.5650, F1 Score: 0.7331\n",
      "Epoch 80, Val Loss: 0.4281, Val Accuracy: 0.5065, Val F1: 0.6068\n",
      "Checkpoint saved at epoch 80.\n",
      "Starting epoch 81/100...\n",
      "Epoch 81, Train Loss: 0.2816, Accuracy: 0.5713, F1 Score: 0.7382\n",
      "Epoch 81, Val Loss: 0.4213, Val Accuracy: 0.5028, Val F1: 0.6087\n",
      "Checkpoint saved at epoch 81.\n",
      "Starting epoch 82/100...\n",
      "Epoch 82, Train Loss: 0.2709, Accuracy: 0.5821, F1 Score: 0.7511\n",
      "Epoch 82, Val Loss: 0.4445, Val Accuracy: 0.4879, Val F1: 0.6068\n",
      "Checkpoint saved at epoch 82.\n",
      "Starting epoch 83/100...\n",
      "Epoch 83, Train Loss: 0.2716, Accuracy: 0.5822, F1 Score: 0.7505\n",
      "Epoch 83, Val Loss: 0.4326, Val Accuracy: 0.4986, Val F1: 0.6095\n",
      "Starting epoch 84/100...\n",
      "Epoch 84, Train Loss: 0.2609, Accuracy: 0.5938, F1 Score: 0.7616\n",
      "Epoch 84, Val Loss: 0.4773, Val Accuracy: 0.5019, Val F1: 0.5987\n",
      "Checkpoint saved at epoch 84.\n",
      "Starting epoch 85/100...\n",
      "Epoch 85, Train Loss: 0.2585, Accuracy: 0.5973, F1 Score: 0.7631\n",
      "Epoch 85, Val Loss: 0.4751, Val Accuracy: 0.4995, Val F1: 0.6011\n",
      "Checkpoint saved at epoch 85.\n",
      "Starting epoch 86/100...\n",
      "Epoch 86, Train Loss: 0.2531, Accuracy: 0.6028, F1 Score: 0.7695\n",
      "Epoch 86, Val Loss: 0.4958, Val Accuracy: 0.4776, Val F1: 0.6003\n",
      "Checkpoint saved at epoch 86.\n",
      "Starting epoch 87/100...\n",
      "Epoch 87, Train Loss: 0.2424, Accuracy: 0.6174, F1 Score: 0.7824\n",
      "Epoch 87, Val Loss: 0.4838, Val Accuracy: 0.5000, Val F1: 0.6093\n",
      "Checkpoint saved at epoch 87.\n",
      "Starting epoch 88/100...\n",
      "Epoch 88, Train Loss: 0.2409, Accuracy: 0.6170, F1 Score: 0.7817\n",
      "Epoch 88, Val Loss: 0.5233, Val Accuracy: 0.4832, Val F1: 0.5851\n",
      "Checkpoint saved at epoch 88.\n",
      "Starting epoch 89/100...\n",
      "Epoch 89, Train Loss: 0.2338, Accuracy: 0.6236, F1 Score: 0.7912\n",
      "Epoch 89, Val Loss: 0.5167, Val Accuracy: 0.4916, Val F1: 0.5990\n",
      "Checkpoint saved at epoch 89.\n",
      "Starting epoch 90/100...\n",
      "Epoch 90, Train Loss: 0.2354, Accuracy: 0.6249, F1 Score: 0.7892\n",
      "Epoch 90, Val Loss: 0.4913, Val Accuracy: 0.4781, Val F1: 0.5985\n",
      "Starting epoch 91/100...\n",
      "Epoch 91, Train Loss: 0.2262, Accuracy: 0.6418, F1 Score: 0.8046\n",
      "Epoch 91, Val Loss: 0.5274, Val Accuracy: 0.4720, Val F1: 0.5996\n",
      "Checkpoint saved at epoch 91.\n",
      "Starting epoch 92/100...\n",
      "Epoch 92, Train Loss: 0.2174, Accuracy: 0.6504, F1 Score: 0.8132\n",
      "Epoch 92, Val Loss: 0.5631, Val Accuracy: 0.4725, Val F1: 0.5824\n",
      "Checkpoint saved at epoch 92.\n",
      "Starting epoch 93/100...\n",
      "Epoch 93, Train Loss: 0.2152, Accuracy: 0.6564, F1 Score: 0.8156\n",
      "Epoch 93, Val Loss: 0.5203, Val Accuracy: 0.4981, Val F1: 0.6114\n",
      "Checkpoint saved at epoch 93.\n",
      "Starting epoch 94/100...\n",
      "Epoch 94, Train Loss: 0.2128, Accuracy: 0.6545, F1 Score: 0.8153\n",
      "Epoch 94, Val Loss: 0.5597, Val Accuracy: 0.4795, Val F1: 0.6024\n",
      "Checkpoint saved at epoch 94.\n",
      "Starting epoch 95/100...\n",
      "Epoch 95, Train Loss: 0.2041, Accuracy: 0.6651, F1 Score: 0.8257\n",
      "Epoch 95, Val Loss: 0.5853, Val Accuracy: 0.4762, Val F1: 0.6053\n",
      "Checkpoint saved at epoch 95.\n",
      "Starting epoch 96/100...\n",
      "Epoch 96, Train Loss: 0.2020, Accuracy: 0.6733, F1 Score: 0.8283\n",
      "Epoch 96, Val Loss: 0.6113, Val Accuracy: 0.4902, Val F1: 0.6001\n",
      "Checkpoint saved at epoch 96.\n",
      "Starting epoch 97/100...\n",
      "Epoch 97, Train Loss: 0.1964, Accuracy: 0.6704, F1 Score: 0.8303\n",
      "Epoch 97, Val Loss: 0.6069, Val Accuracy: 0.4716, Val F1: 0.5931\n",
      "Checkpoint saved at epoch 97.\n",
      "Starting epoch 98/100...\n",
      "Epoch 98, Train Loss: 0.1920, Accuracy: 0.6842, F1 Score: 0.8425\n",
      "Epoch 98, Val Loss: 0.6241, Val Accuracy: 0.4958, Val F1: 0.6096\n",
      "Checkpoint saved at epoch 98.\n",
      "Starting epoch 99/100...\n",
      "Epoch 99, Train Loss: 0.1924, Accuracy: 0.6767, F1 Score: 0.8372\n",
      "Epoch 99, Val Loss: 0.5897, Val Accuracy: 0.4753, Val F1: 0.6061\n",
      "Starting epoch 100/100...\n",
      "Epoch 100, Train Loss: 0.1860, Accuracy: 0.6925, F1 Score: 0.8457\n",
      "Epoch 100, Val Loss: 0.6458, Val Accuracy: 0.4986, Val F1: 0.6064\n",
      "Checkpoint saved at epoch 100.\n",
      "Best model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_177267/2188939409.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    }
   ],
   "source": [
    "from timm.models import deit_base_distilled_patch16_224\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDeiT_base(nn.Module):\n",
    "    def __init__(self, pretrained=False, num_classes=5, drop_rate=0.2):\n",
    "        super(CustomDeiT_base, self).__init__()\n",
    "        self.model = deit_base_distilled_patch16_224(pretrained=pretrained, num_classes=num_classes)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.model(x)\n",
    "        if isinstance(outputs, tuple):\n",
    "            x1, x2 = outputs\n",
    "            avg_output = (x1 + x2) / 2\n",
    "        else:\n",
    "            avg_output = outputs\n",
    "\n",
    "        return self.dropout(avg_output)\n",
    "\n",
    "deit_base_model = CustomDeiT_base(pretrained=False, num_classes=5, drop_rate=0.2).to(device)\n",
    "\n",
    "logs_base = train_model(\n",
    "    model=deit_base_model,\n",
    "    train_loader=train_loader,  # 제공된 학습 데이터 로더\n",
    "    val_loader=val_loader,      # 제공된 검증 데이터 로더\n",
    "    num_epochs=100,              # 총 학습 epoch 수\n",
    "    patience=5,                 # 조기 종료를 위한 patience\n",
    "    learning_rate=0.0001,       # 최적 학습률\n",
    "    checkpoint_path='best_deit_base_model.pth'  # 체크포인트 저장 경로\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T7QWIxLvM0Bi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Loss: 0.6458\n",
      "Validation Accuracy: 0.4986\n",
      "Validation F1 Score: 0.6064\n",
      "Evaluating on test set...\n",
      "Test Loss: 0.6835\n",
      "Test Accuracy: 0.4852\n",
      "Test F1 Score: 0.5932\n"
     ]
    }
   ],
   "source": [
    "validation_loader = DataLoader(\n",
    "    ECGDataset(X_val, y_val_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_loss, val_accuracy, val_f1 = evaluate_model(deit_base_model, validation_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_loader = DataLoader(\n",
    "    ECGDataset(X_test, y_test_bin, transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_accuracy, test_f1 = evaluate_model(deit_base_model, test_loader, nn.BCEWithLogitsLoss())\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "group4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
