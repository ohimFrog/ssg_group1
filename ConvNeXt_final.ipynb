{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [심층신경망개론] Group 1 ConvNeXt 구현\n",
    "- [ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders](https://arxiv.org/pdf/2301.00808)\n",
    "- [GitHub](https://github.com/facebookresearch/ConvNeXt-V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- ConvNeXt Input 형식에 맞게 [224x224] 크기의 이미지 생성\n",
    "- ConvNeXt Input channel은 RGB로 3임. (모델 또는 Dataset 수정)\n",
    "- PTB-XL 데이터셋은 ECG 파형뿐만 아니라, 환자 정보를 담고 있음. (Multi-modal)\n",
    "    - [An Improved ConvNeXt with Multimodal Transformer for Physiological Signal Classification](https://vuir.vu.edu.au/48410/1/An_Improved_ConvNeXt_with_Multimodal_Transformer_for_Physiological_Signal_Classification.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    \"\"\"df.index를 기준으로 데이터를 로드\"\"\"\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_lr']]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(os.path.join(path, f)) for f in df['filename_hr']]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "# 데이터 경로 설정\n",
    "path = r\"C:\\Users\\은혁\\Desktop\\심신개 Project\\Data\\ptbxl\"\n",
    "sampling_rate = 100\n",
    "\n",
    "# PTB-XL 데이터베이스 로드\n",
    "df = pd.read_csv(os.path.join(path, 'ptbxl_database.csv'), index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# 진단 정보 로드\n",
    "agg_df = pd.read_csv(os.path.join(path, 'scp_statements.csv'), index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    \"\"\"진단 클래스를 매핑하는 함수\"\"\"\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "df['diagnostic_superclass'] = df.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "df = df[df['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Raw data 로드\n",
    "X = load_raw_data(df, sampling_rate, path)\n",
    "assert len(X) == len(df), \"X와 df의 크기가 일치하지 않습니다.\"\n",
    "\n",
    "# 데이터셋 분리\n",
    "test_fold = 10\n",
    "val_fold = 9\n",
    "\n",
    "train_filter = (df.strat_fold != test_fold) & (df.strat_fold != val_fold)\n",
    "val_filter = df.strat_fold == val_fold\n",
    "test_filter = df.strat_fold == test_fold\n",
    "\n",
    "X_train = X[train_filter]\n",
    "y_train = list(df[train_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_val = X[val_filter]\n",
    "y_val = list(df[val_filter]['diagnostic_superclass'])\n",
    "\n",
    "X_test = X[test_filter]\n",
    "y_test = list(df[test_filter]['diagnostic_superclass'])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Labels: {y_train_bin.shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}, Labels: {y_val_bin.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}, Labels: {y_test_bin.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n",
      "Train dataset length: 17084\n",
      "Validation dataset length: 2146\n",
      "Test dataset length: 2158\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, DeiTForImageClassification\n",
    "from torchvision.models import convnext_tiny, efficientnet_v2_s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configurations ---\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 40,\n",
    "    \"model\": \"convnextv2_tiny\",\n",
    "    \"input_size\": 224,\n",
    "    \"lr\": 4e-3,\n",
    "    \"weight_decay\": 0.05,\n",
    "    # \"warmup_epochs\": 20,\n",
    "    # \"mixup\": 0.8,\n",
    "    # \"cutmix\": 1.0,\n",
    "    # \"smoothing\": 0.1,\n",
    "    \"data_path\": path,\n",
    "    \"output_dir\": r\"C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\convnextv2_tiny\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"num_workers\": 0,\n",
    "    \"use_amp\": False,\n",
    "}\n",
    "\n",
    "# --- Data Preparation ---\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample.float(), torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Numpy 배열 -> Tensor\n",
    "    transforms.Resize((182, 256)),  # 이미지 크기 조정\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),  # 1채널 데이터를 3채널로 확장\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomResizedCrop(args[\"input_size\"]),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# --- Data Loader ---\n",
    "train_dataset = ECGDataset(X_train, y_train_bin, transform=transform)\n",
    "valid_dataset = ECGDataset(X_val, y_val_bin, transform=transform)\n",
    "test_dataset = ECGDataset(X_test, y_test_bin, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class_names = mlb.classes_\n",
    "print(f\"\\nClasses: {class_names}\")\n",
    "\n",
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.9919, -0.9919, -0.9919,  ..., -0.7681, -0.7681, -0.7681],\n",
       "           [-0.9504, -0.9504, -0.9504,  ..., -0.7193, -0.7193, -0.7193],\n",
       "           [-0.9964, -0.9964, -0.9964,  ..., -0.8101, -0.8101, -0.8101],\n",
       "           ...,\n",
       "           [-1.2031, -1.2031, -1.2031,  ..., -0.9059, -0.9059, -0.9059],\n",
       "           [-1.1189, -1.1189, -1.1189,  ..., -0.8946, -0.8946, -0.8946],\n",
       "           [-1.0773, -1.0773, -1.0773,  ..., -0.8185, -0.8185, -0.8185]],\n",
       " \n",
       "          [[-0.9919, -0.9919, -0.9919,  ..., -0.7681, -0.7681, -0.7681],\n",
       "           [-0.9504, -0.9504, -0.9504,  ..., -0.7193, -0.7193, -0.7193],\n",
       "           [-0.9964, -0.9964, -0.9964,  ..., -0.8101, -0.8101, -0.8101],\n",
       "           ...,\n",
       "           [-1.2031, -1.2031, -1.2031,  ..., -0.9059, -0.9059, -0.9059],\n",
       "           [-1.1189, -1.1189, -1.1189,  ..., -0.8946, -0.8946, -0.8946],\n",
       "           [-1.0773, -1.0773, -1.0773,  ..., -0.8185, -0.8185, -0.8185]],\n",
       " \n",
       "          [[-0.9919, -0.9919, -0.9919,  ..., -0.7681, -0.7681, -0.7681],\n",
       "           [-0.9504, -0.9504, -0.9504,  ..., -0.7193, -0.7193, -0.7193],\n",
       "           [-0.9964, -0.9964, -0.9964,  ..., -0.8101, -0.8101, -0.8101],\n",
       "           ...,\n",
       "           [-1.2031, -1.2031, -1.2031,  ..., -0.9059, -0.9059, -0.9059],\n",
       "           [-1.1189, -1.1189, -1.1189,  ..., -0.8946, -0.8946, -0.8946],\n",
       "           [-1.0773, -1.0773, -1.0773,  ..., -0.8185, -0.8185, -0.8185]]],\n",
       " \n",
       " \n",
       "         [[[-1.0399, -1.0399, -1.0399,  ..., -1.0815, -1.0815, -1.0815],\n",
       "           [-1.0329, -1.0329, -1.0329,  ..., -1.1213, -1.1213, -1.1213],\n",
       "           [-0.8455, -0.8455, -0.8455,  ..., -0.7735, -0.7735, -0.7735],\n",
       "           ...,\n",
       "           [-0.9320, -0.9320, -0.9320,  ..., -0.9577, -0.9577, -0.9577],\n",
       "           [-1.0223, -1.0223, -1.0223,  ..., -0.9701, -0.9701, -0.9701],\n",
       "           [-1.0583, -1.0583, -1.0583,  ..., -1.0648, -1.0648, -1.0648]],\n",
       " \n",
       "          [[-1.0399, -1.0399, -1.0399,  ..., -1.0815, -1.0815, -1.0815],\n",
       "           [-1.0329, -1.0329, -1.0329,  ..., -1.1213, -1.1213, -1.1213],\n",
       "           [-0.8455, -0.8455, -0.8455,  ..., -0.7735, -0.7735, -0.7735],\n",
       "           ...,\n",
       "           [-0.9320, -0.9320, -0.9320,  ..., -0.9577, -0.9577, -0.9577],\n",
       "           [-1.0223, -1.0223, -1.0223,  ..., -0.9701, -0.9701, -0.9701],\n",
       "           [-1.0583, -1.0583, -1.0583,  ..., -1.0648, -1.0648, -1.0648]],\n",
       " \n",
       "          [[-1.0399, -1.0399, -1.0399,  ..., -1.0815, -1.0815, -1.0815],\n",
       "           [-1.0329, -1.0329, -1.0329,  ..., -1.1213, -1.1213, -1.1213],\n",
       "           [-0.8455, -0.8455, -0.8455,  ..., -0.7735, -0.7735, -0.7735],\n",
       "           ...,\n",
       "           [-0.9320, -0.9320, -0.9320,  ..., -0.9577, -0.9577, -0.9577],\n",
       "           [-1.0223, -1.0223, -1.0223,  ..., -0.9701, -0.9701, -0.9701],\n",
       "           [-1.0583, -1.0583, -1.0583,  ..., -1.0648, -1.0648, -1.0648]]],\n",
       " \n",
       " \n",
       "         [[[-1.2121, -1.2121, -1.2121,  ..., -1.4598, -1.4598, -1.4598],\n",
       "           [-1.2263, -1.2263, -1.2263,  ..., -1.4455, -1.4455, -1.4455],\n",
       "           [-1.1621, -1.1621, -1.1621,  ..., -1.4103, -1.4103, -1.4103],\n",
       "           ...,\n",
       "           [-0.9843, -0.9843, -0.9843,  ..., -1.1952, -1.1952, -1.1952],\n",
       "           [-1.0766, -1.0766, -1.0766,  ..., -1.2784, -1.2784, -1.2784],\n",
       "           [-1.1043, -1.1043, -1.1043,  ..., -1.2935, -1.2935, -1.2935]],\n",
       " \n",
       "          [[-1.2121, -1.2121, -1.2121,  ..., -1.4598, -1.4598, -1.4598],\n",
       "           [-1.2263, -1.2263, -1.2263,  ..., -1.4455, -1.4455, -1.4455],\n",
       "           [-1.1621, -1.1621, -1.1621,  ..., -1.4103, -1.4103, -1.4103],\n",
       "           ...,\n",
       "           [-0.9843, -0.9843, -0.9843,  ..., -1.1952, -1.1952, -1.1952],\n",
       "           [-1.0766, -1.0766, -1.0766,  ..., -1.2784, -1.2784, -1.2784],\n",
       "           [-1.1043, -1.1043, -1.1043,  ..., -1.2935, -1.2935, -1.2935]],\n",
       " \n",
       "          [[-1.2121, -1.2121, -1.2121,  ..., -1.4598, -1.4598, -1.4598],\n",
       "           [-1.2263, -1.2263, -1.2263,  ..., -1.4455, -1.4455, -1.4455],\n",
       "           [-1.1621, -1.1621, -1.1621,  ..., -1.4103, -1.4103, -1.4103],\n",
       "           ...,\n",
       "           [-0.9843, -0.9843, -0.9843,  ..., -1.1952, -1.1952, -1.1952],\n",
       "           [-1.0766, -1.0766, -1.0766,  ..., -1.2784, -1.2784, -1.2784],\n",
       "           [-1.1043, -1.1043, -1.1043,  ..., -1.2935, -1.2935, -1.2935]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.4381, -0.4381, -0.4381,  ..., -1.0211, -1.0211, -1.0211],\n",
       "           [-0.7339, -0.7339, -0.7339,  ..., -1.1332, -1.1332, -1.1332],\n",
       "           [-1.1478, -1.1478, -1.1478,  ..., -1.4772, -1.4772, -1.4772],\n",
       "           ...,\n",
       "           [-1.0929, -1.0929, -1.0929,  ..., -0.6588, -0.6588, -0.6588],\n",
       "           [-1.1259, -1.1259, -1.1259,  ..., -0.6820, -0.6820, -0.6820],\n",
       "           [-1.1560, -1.1560, -1.1560,  ..., -0.6913, -0.6913, -0.6913]],\n",
       " \n",
       "          [[-0.4381, -0.4381, -0.4381,  ..., -1.0211, -1.0211, -1.0211],\n",
       "           [-0.7339, -0.7339, -0.7339,  ..., -1.1332, -1.1332, -1.1332],\n",
       "           [-1.1478, -1.1478, -1.1478,  ..., -1.4772, -1.4772, -1.4772],\n",
       "           ...,\n",
       "           [-1.0929, -1.0929, -1.0929,  ..., -0.6588, -0.6588, -0.6588],\n",
       "           [-1.1259, -1.1259, -1.1259,  ..., -0.6820, -0.6820, -0.6820],\n",
       "           [-1.1560, -1.1560, -1.1560,  ..., -0.6913, -0.6913, -0.6913]],\n",
       " \n",
       "          [[-0.4381, -0.4381, -0.4381,  ..., -1.0211, -1.0211, -1.0211],\n",
       "           [-0.7339, -0.7339, -0.7339,  ..., -1.1332, -1.1332, -1.1332],\n",
       "           [-1.1478, -1.1478, -1.1478,  ..., -1.4772, -1.4772, -1.4772],\n",
       "           ...,\n",
       "           [-1.0929, -1.0929, -1.0929,  ..., -0.6588, -0.6588, -0.6588],\n",
       "           [-1.1259, -1.1259, -1.1259,  ..., -0.6820, -0.6820, -0.6820],\n",
       "           [-1.1560, -1.1560, -1.1560,  ..., -0.6913, -0.6913, -0.6913]]],\n",
       " \n",
       " \n",
       "         [[[-1.0555, -1.0555, -1.0555,  ..., -1.3001, -1.3001, -1.3001],\n",
       "           [-1.0713, -1.0713, -1.0713,  ..., -1.3060, -1.3060, -1.3060],\n",
       "           [-1.0813, -1.0813, -1.0813,  ..., -1.3170, -1.3170, -1.3170],\n",
       "           ...,\n",
       "           [-0.6360, -0.6360, -0.6360,  ..., -0.2048, -0.2048, -0.2048],\n",
       "           [-0.6448, -0.6448, -0.6448,  ..., -0.0845, -0.0845, -0.0845],\n",
       "           [-0.8921, -0.8921, -0.8921,  ..., -0.6330, -0.6330, -0.6330]],\n",
       " \n",
       "          [[-1.0555, -1.0555, -1.0555,  ..., -1.3001, -1.3001, -1.3001],\n",
       "           [-1.0713, -1.0713, -1.0713,  ..., -1.3060, -1.3060, -1.3060],\n",
       "           [-1.0813, -1.0813, -1.0813,  ..., -1.3170, -1.3170, -1.3170],\n",
       "           ...,\n",
       "           [-0.6360, -0.6360, -0.6360,  ..., -0.2048, -0.2048, -0.2048],\n",
       "           [-0.6448, -0.6448, -0.6448,  ..., -0.0845, -0.0845, -0.0845],\n",
       "           [-0.8921, -0.8921, -0.8921,  ..., -0.6330, -0.6330, -0.6330]],\n",
       " \n",
       "          [[-1.0555, -1.0555, -1.0555,  ..., -1.3001, -1.3001, -1.3001],\n",
       "           [-1.0713, -1.0713, -1.0713,  ..., -1.3060, -1.3060, -1.3060],\n",
       "           [-1.0813, -1.0813, -1.0813,  ..., -1.3170, -1.3170, -1.3170],\n",
       "           ...,\n",
       "           [-0.6360, -0.6360, -0.6360,  ..., -0.2048, -0.2048, -0.2048],\n",
       "           [-0.6448, -0.6448, -0.6448,  ..., -0.0845, -0.0845, -0.0845],\n",
       "           [-0.8921, -0.8921, -0.8921,  ..., -0.6330, -0.6330, -0.6330]]],\n",
       " \n",
       " \n",
       "         [[[-1.0006, -1.0006, -1.0006,  ..., -0.9785, -0.9785, -0.9785],\n",
       "           [-0.9131, -0.9131, -0.9131,  ..., -0.9173, -0.9173, -0.9173],\n",
       "           [-0.9216, -0.9216, -0.9216,  ..., -0.9356, -0.9356, -0.9356],\n",
       "           ...,\n",
       "           [-1.3654, -1.3654, -1.3654,  ..., -1.4549, -1.4549, -1.4549],\n",
       "           [-1.3501, -1.3501, -1.3501,  ..., -1.6663, -1.6663, -1.6663],\n",
       "           [-1.5174, -1.5174, -1.5174,  ..., -1.8545, -1.8545, -1.8545]],\n",
       " \n",
       "          [[-1.0006, -1.0006, -1.0006,  ..., -0.9785, -0.9785, -0.9785],\n",
       "           [-0.9131, -0.9131, -0.9131,  ..., -0.9173, -0.9173, -0.9173],\n",
       "           [-0.9216, -0.9216, -0.9216,  ..., -0.9356, -0.9356, -0.9356],\n",
       "           ...,\n",
       "           [-1.3654, -1.3654, -1.3654,  ..., -1.4549, -1.4549, -1.4549],\n",
       "           [-1.3501, -1.3501, -1.3501,  ..., -1.6663, -1.6663, -1.6663],\n",
       "           [-1.5174, -1.5174, -1.5174,  ..., -1.8545, -1.8545, -1.8545]],\n",
       " \n",
       "          [[-1.0006, -1.0006, -1.0006,  ..., -0.9785, -0.9785, -0.9785],\n",
       "           [-0.9131, -0.9131, -0.9131,  ..., -0.9173, -0.9173, -0.9173],\n",
       "           [-0.9216, -0.9216, -0.9216,  ..., -0.9356, -0.9356, -0.9356],\n",
       "           ...,\n",
       "           [-1.3654, -1.3654, -1.3654,  ..., -1.4549, -1.4549, -1.4549],\n",
       "           [-1.3501, -1.3501, -1.3501,  ..., -1.6663, -1.6663, -1.6663],\n",
       "           [-1.5174, -1.5174, -1.5174,  ..., -1.8545, -1.8545, -1.8545]]]]),\n",
       " tensor([[0, 0, 0, 1, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 1, 0, 1],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\vingt\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\anaconda3\\envs\\vingt\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "C:\\Users\\은혁\\AppData\\Local\\Temp\\ipykernel_26944\\2224499961.py:151: UserWarning: Overwriting convnext_tiny in registry with __main__.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_tiny(pretrained=False,in_22k=False, **kwargs):\n",
      "C:\\Users\\은혁\\AppData\\Local\\Temp\\ipykernel_26944\\2224499961.py:163: UserWarning: Overwriting convnext_small in registry with __main__.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_small(pretrained=False,in_22k=False, **kwargs):\n",
      "C:\\Users\\은혁\\AppData\\Local\\Temp\\ipykernel_26944\\2224499961.py:175: UserWarning: Overwriting convnext_base in registry with __main__.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_base(pretrained=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\은혁\\AppData\\Local\\Temp\\ipykernel_26944\\2224499961.py:187: UserWarning: Overwriting convnext_large in registry with __main__.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_large(pretrained=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\은혁\\AppData\\Local\\Temp\\ipykernel_26944\\2224499961.py:199: UserWarning: Overwriting convnext_xlarge in registry with __main__.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "class GRN(nn.Module):\n",
    "    \"\"\" GRN (Global Response Normalization) layer\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Gx = torch.norm(x, p=2, dim=(1,2), keepdim=True)\n",
    "        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
    "        return self.gamma * (x * Nx) + self.beta + x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" ConvNeXtV2 Block.\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.grn = GRN(4 * dim)\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.grn(x)\n",
    "        x = self.pwconv2(x)\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "class ConvNeXtV2(nn.Module):\n",
    "    \"\"\" ConvNeXt V2\n",
    "        \n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], \n",
    "                 drop_path_rate=0., head_init_scale=1.\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j]) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "def convnextv2_atto(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[2, 2, 6, 2], dims=[40, 80, 160, 320], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_femto(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[2, 2, 6, 2], dims=[48, 96, 192, 384], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnext_pico(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[2, 2, 6, 2], dims=[64, 128, 256, 512], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_nano(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[2, 2, 8, 2], dims=[80, 160, 320, 640], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_tiny(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_base(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_large(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n",
    "    return model\n",
    "\n",
    "def convnextv2_huge(**kwargs):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 27, 3], dims=[352, 704, 1408, 2816], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from timm import create_model\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "\n",
    "# --- Model Setup ---\n",
    "model = create_model(args[\"model\"], pretrained=False, num_classes=y_train_bin.shape[1])\n",
    "model = model.to(args[\"device\"])\n",
    "\n",
    "criterion = SoftTargetCrossEntropy()\n",
    "#criterion = LabelSmoothingCrossEntropy(smoothing=args[\"smoothing\"])\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args[\"lr\"], weight_decay=args[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args[\"epochs\"])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/40: 100%|██████████████████████████████████████| 1068/1068 [05:49<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 2.0653, Accuracy: 0.4042, F1 Score: 0.2672, Precision: 0.2743, Recall: 0.4042\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1/40: 100%|██████████████████████████████████████| 135/135 [00:14<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9858, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/40: 100%|██████████████████████████████████████| 1068/1068 [05:50<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40], Loss: 1.9938, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2/40: 100%|██████████████████████████████████████| 135/135 [00:15<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9923, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/40: 100%|██████████████████████████████████████| 1068/1068 [06:03<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40], Loss: 1.9940, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 3/40: 100%|██████████████████████████████████████| 135/135 [00:15<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9851, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/40: 100%|██████████████████████████████████████| 1068/1068 [06:11<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40], Loss: 1.9929, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 4/40: 100%|██████████████████████████████████████| 135/135 [00:21<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9847, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/40: 100%|██████████████████████████████████████| 1068/1068 [06:36<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40], Loss: 1.9933, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 5/40: 100%|██████████████████████████████████████| 135/135 [00:19<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9839, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/40: 100%|██████████████████████████████████████| 1068/1068 [06:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40], Loss: 1.9927, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 6/40: 100%|██████████████████████████████████████| 135/135 [00:18<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9862, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/40: 100%|██████████████████████████████████████| 1068/1068 [06:19<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40], Loss: 1.9923, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 7/40: 100%|██████████████████████████████████████| 135/135 [00:20<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9840, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/40: 100%|██████████████████████████████████████| 1068/1068 [06:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40], Loss: 1.9932, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 8/40: 100%|██████████████████████████████████████| 135/135 [00:14<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9862, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/40: 100%|██████████████████████████████████████| 1068/1068 [05:52<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40], Loss: 1.9931, Accuracy: 0.4247, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4247\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 9/40: 100%|██████████████████████████████████████| 135/135 [00:14<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9863, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/40: 100%|█████████████████████████████████████| 1068/1068 [05:52<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], Loss: 1.9935, Accuracy: 0.4238, F1 Score: 0.2535, Precision: 0.1830, Recall: 0.4238\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 10/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9863, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/40: 100%|█████████████████████████████████████| 1068/1068 [05:38<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40], Loss: 1.9937, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_11.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 11/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9873, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/40: 100%|█████████████████████████████████████| 1068/1068 [05:34<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40], Loss: 1.9922, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 12/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9861, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/40: 100%|█████████████████████████████████████| 1068/1068 [05:29<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40], Loss: 1.9920, Accuracy: 0.4243, F1 Score: 0.2533, Precision: 0.1806, Recall: 0.4243\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 13/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9844, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/40: 100%|█████████████████████████████████████| 1068/1068 [05:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40], Loss: 1.9921, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 14/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9852, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/40: 100%|█████████████████████████████████████| 1068/1068 [05:29<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40], Loss: 1.9924, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 15/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9903, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/40: 100%|█████████████████████████████████████| 1068/1068 [05:25<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40], Loss: 1.9926, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 16/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9855, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/40: 100%|█████████████████████████████████████| 1068/1068 [05:32<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40], Loss: 1.9925, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 17/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9866, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/40: 100%|█████████████████████████████████████| 1068/1068 [05:16<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40], Loss: 1.9914, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 18/40: 100%|█████████████████████████████████████| 135/135 [00:11<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/40: 100%|█████████████████████████████████████| 1068/1068 [04:18<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40], Loss: 1.9917, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 19/40: 100%|█████████████████████████████████████| 135/135 [00:12<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9846, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/40: 100%|█████████████████████████████████████| 1068/1068 [04:18<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40], Loss: 1.9917, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 20/40: 100%|█████████████████████████████████████| 135/135 [00:11<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/40: 100%|█████████████████████████████████████| 1068/1068 [04:36<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40], Loss: 1.9915, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_21.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 21/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/40: 100%|█████████████████████████████████████| 1068/1068 [05:15<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40], Loss: 1.9913, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_22.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 22/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9839, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/40: 100%|█████████████████████████████████████| 1068/1068 [05:20<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40], Loss: 1.9909, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_23.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 23/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9849, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/40: 100%|█████████████████████████████████████| 1068/1068 [05:07<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/40], Loss: 1.9911, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 24/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9845, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/40: 100%|█████████████████████████████████████| 1068/1068 [05:19<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/40], Loss: 1.9909, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_25.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 25/40: 100%|█████████████████████████████████████| 135/135 [00:12<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9838, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/40: 100%|█████████████████████████████████████| 1068/1068 [04:52<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/40], Loss: 1.9908, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 26/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9846, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/40: 100%|█████████████████████████████████████| 1068/1068 [04:40<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/40], Loss: 1.9907, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_27.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 27/40: 100%|█████████████████████████████████████| 135/135 [00:12<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9838, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/40: 100%|█████████████████████████████████████| 1068/1068 [04:31<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/40], Loss: 1.9907, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_28.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 28/40: 100%|█████████████████████████████████████| 135/135 [00:11<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9841, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/40: 100%|█████████████████████████████████████| 1068/1068 [04:44<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/40], Loss: 1.9903, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_29.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 29/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/40: 100%|█████████████████████████████████████| 1068/1068 [05:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/40], Loss: 1.9902, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 30/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9844, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/40: 100%|█████████████████████████████████████| 1068/1068 [05:36<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/40], Loss: 1.9901, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_31.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 31/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9837, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/40: 100%|█████████████████████████████████████| 1068/1068 [05:44<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/40], Loss: 1.9900, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_32.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 32/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9839, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/40: 100%|█████████████████████████████████████| 1068/1068 [05:55<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/40], Loss: 1.9899, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_33.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 33/40: 100%|█████████████████████████████████████| 135/135 [00:14<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9838, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/40: 100%|█████████████████████████████████████| 1068/1068 [05:56<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/40], Loss: 1.9899, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 34/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/40: 100%|█████████████████████████████████████| 1068/1068 [05:09<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/40], Loss: 1.9898, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_35.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 35/40: 100%|█████████████████████████████████████| 135/135 [00:12<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9837, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/40: 100%|█████████████████████████████████████| 1068/1068 [05:31<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/40], Loss: 1.9897, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_36.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 36/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/40: 100%|█████████████████████████████████████| 1068/1068 [05:20<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/40], Loss: 1.9898, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_37.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 37/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/40: 100%|█████████████████████████████████████| 1068/1068 [05:19<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/40], Loss: 1.9898, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_38.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 38/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/40: 100%|█████████████████████████████████████| 1068/1068 [05:19<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/40], Loss: 1.9897, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_39.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 39/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/40: 100%|█████████████████████████████████████| 1068/1068 [05:21<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/40], Loss: 1.9897, Accuracy: 0.4251, F1 Score: 0.2536, Precision: 0.1807, Recall: 0.4251\n",
      "Model saved at C:\\Users\\은혁\\Desktop\\심신개 Project\\checkpoints\\ConvNeXt_epoch_40.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 40/40: 100%|█████████████████████████████████████| 135/135 [00:13<00:00, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9836, Accuracy: 0.4278, F1 Score: 0.2563, Precision: 0.1830, Recall: 0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "save_dir = args[\"output_dir\"]\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# --- Training Loop ---\n",
    "scaler = torch.amp.GradScaler(enabled=args[\"use_amp\"])\n",
    "for epoch in range(args[\"epochs\"]):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{args['epochs']}\", ncols=100):\n",
    "        images, labels = images.to(args[\"device\"]), labels.to(args[\"device\"])\n",
    "\n",
    "        \"\"\"\n",
    "        if mixup_fn is not None:\n",
    "            images, labels = mixup_fn(images, labels)\n",
    "        \"\"\"\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_labels.append(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "\n",
    "    scheduler.step()\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    train_accuracy = (all_preds == all_labels).mean()\n",
    "    train_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    train_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{args['epochs']}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "          f\"Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}, \"\n",
    "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}\")\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f\"ConvNeXtV2_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved at {save_path}\")\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader, desc=f\"Validating Epoch {epoch+1}/{args['epochs']}\", ncols=100):\n",
    "            images, labels = images.to(args[\"device\"]), labels.to(args[\"device\"])\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            all_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            all_labels.append(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    val_accuracy = (all_preds == all_labels).mean()\n",
    "    val_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    val_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Validation Loss: {valid_loss/len(valid_loader):.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
    "          f\"F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9795, Accuracy: 0.4245, F1 Score: 0.2530, Precision: 0.1802, Recall: 0.4245\n"
     ]
    }
   ],
   "source": [
    "# --- Test Loop ---\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(args[\"device\"]), labels.to(args[\"device\"])\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        all_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_labels.append(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "test_accuracy = (all_preds == all_labels).mean()\n",
    "test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "test_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Accuracy: {test_accuracy:.4f}, \"\n",
    "      f\"F1 Score: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vingt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
